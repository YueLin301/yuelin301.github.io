---
title: Information Design in Multi-Agent Reinforcement Learning
date: 2023-11-24 02:40:00 +0800
categories: [Artificial Intelligence, Multi-Agent Reinforcement Learning]
tags: [Tech, AI, Multi Agents, RL, Game Theory, Social Dilemma, Information Design, My Work]
math: True
---


## Key Points
1. Mixed-motive between two agents. Some other MARL papers use the term "mixed-motive" to describe scenarios involving two groups of agents, where agents within the same group cooperate but have conflicts with agents from the other group.
2. Non-stationarity. 
   1. Signals should not be viewed as actions. 
   2. Signals affects the others' "environment".
3. Signaling Gradient is not only suitable for mixed-motive communication, but is also suitable for fully-cooperative communication.
4. Information design is far more difficult than incentive design.
   1. Signal can be ignored. Incentive is compulsory. In the training beginning, the signaling scheme is almost random, the receiver will easily learn to ignore the messages, and this case is a strong equilibrium.
   2. Signals immediately changes transitions (it affects both the sampling phase and the update phase of RL). Reward does not affect trajectory (it only affects the update phase of RL). So the hyper-gradient method used in LIO is not applicable here (the first-order gradient from the sampling phase is dominant).
   3. The sender cannot take environmental actions. It only can get feedback from the receiver's actions.
5. The sender and the receiver are rational (in a sense of RL), self-interested, and risk-neutral.
6. The receiver's policy is Markovian, not history-dependent. At every timestep, it takes actions based on the current estimation of the future payoffs. So the obedience constraint can be easily extended in MSGs.
7. In the learning scenario, we can cancel the commitment assumption and the analysis of the revelation principle.

## Interesting Experimental Results
1. The DIAL sender does not concern about itself at all.
2. Symmetricity. Emergent Languages.
3. Honesty of the sender can be manipuated by the hyperparameters of the Lagrangian method, as shown in the heatmap in Appendix H.6.
4. The more the receiver can see, the less the informational adavantage the sender has, the less the sender can manipulate, as shown in the Appendix H.7.

> The following part has not been finished yet.
{: .prompt-warning }