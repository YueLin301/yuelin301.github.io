<!doctype html>














<!-- `site.alt_lang` can specify a language different from the UI -->
<html lang="en" >
  <!-- The Head -->

<head>
  <meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
  <meta name="theme-color" media="(prefers-color-scheme: light)" content="#f7f7f7">
  <meta name="theme-color" media="(prefers-color-scheme: dark)" content="#1b1b1e">
  <meta name="apple-mobile-web-app-capable" content="yes">
  <meta name="apple-mobile-web-app-status-bar-style" content="black-translucent">
  <meta
    name="viewport"
    content="width=device-width, user-scalable=no initial-scale=1, shrink-to-fit=no, viewport-fit=cover"
  >

  

  

  
    <!-- Begin Jekyll SEO tag v2.8.0 -->
<meta name="generator" content="Jekyll v4.3.2" />
<meta property="og:title" content="Sequence-to-Sequence Models" />
<meta property="og:locale" content="en" />
<meta name="description" content="NLP Terms" />
<meta property="og:description" content="NLP Terms" />
<link rel="canonical" href="http://localhost:4000/posts/Seq2Seq/" />
<meta property="og:url" content="http://localhost:4000/posts/Seq2Seq/" />
<meta property="og:site_name" content="Yue Lin" />
<meta property="og:type" content="article" />
<meta property="article:published_time" content="2023-07-15T18:40:00+00:00" />
<meta name="twitter:card" content="summary" />
<meta property="twitter:title" content="Sequence-to-Sequence Models" />
<meta name="google-site-verification" content="d2Lg5eCqHini4wHtZ-c84NNCK97UHcbAhQzVJHekMZQ" />
<script type="application/ld+json">
{"@context":"https://schema.org","@type":"BlogPosting","dateModified":"2023-12-19T13:49:18+00:00","datePublished":"2023-07-15T18:40:00+00:00","description":"NLP Terms","headline":"Sequence-to-Sequence Models","mainEntityOfPage":{"@type":"WebPage","@id":"http://localhost:4000/posts/Seq2Seq/"},"url":"http://localhost:4000/posts/Seq2Seq/"}</script>
<!-- End Jekyll SEO tag -->

  

  <title>Sequence-to-Sequence Models | Yue Lin
  </title>

  <!--
  The Favicons for Web, Android, Microsoft, and iOS (iPhone and iPad) Apps
  Generated by: https://realfavicongenerator.net/
-->



<link rel="apple-touch-icon" sizes="180x180" href="/assets/img/favicons/apple-touch-icon.png">
<link rel="icon" type="image/png" sizes="32x32" href="/assets/img/favicons/favicon-32x32.png">
<link rel="icon" type="image/png" sizes="16x16" href="/assets/img/favicons/favicon-16x16.png">
<link rel="manifest" href="/assets/img/favicons/site.webmanifest">
<link rel="shortcut icon" href="/assets/img/favicons/favicon.ico">
<meta name="apple-mobile-web-app-title" content="Yue Lin">
<meta name="application-name" content="Yue Lin">
<meta name="msapplication-TileColor" content="#da532c">
<meta name="msapplication-config" content="/assets/img/favicons/browserconfig.xml">
<meta name="theme-color" content="#ffffff">


  
    
      <link rel="preconnect" href="https://fonts.googleapis.com" >
      <link rel="dns-prefetch" href="https://fonts.googleapis.com" >
    
      <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
      <link rel="dns-prefetch" href="https://fonts.gstatic.com" crossorigin>
    
      <link rel="preconnect" href="https://fonts.googleapis.com" >
      <link rel="dns-prefetch" href="https://fonts.googleapis.com" >
    
      <link rel="preconnect" href="https://cdn.jsdelivr.net" >
      <link rel="dns-prefetch" href="https://cdn.jsdelivr.net" >
    

    <link rel="stylesheet" href="https://fonts.googleapis.com/css2?family=Lato&family=Source+Sans+Pro:wght@400;600;700;900&display=swap">
  

  <!-- GA -->
  

  <!-- Bootstrap -->
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/bootstrap@5.3.2/dist/css/bootstrap.min.css">

  <!-- Font Awesome -->
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@6.4.2/css/all.min.css">

  <link rel="stylesheet" href="/assets/css/jekyll-theme-chirpy.css">

  
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/tocbot@4.21.1/dist/tocbot.min.css">
  

  
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/loading-attribute-polyfill@2.1.1/dist/loading-attribute-polyfill.min.css">
  

  
    <!-- Manific Popup -->
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/magnific-popup@1.1.0/dist/magnific-popup.min.css">
  

  <!-- JavaScript -->

  
    <!-- Switch the mode between dark and light. -->

<script type="text/javascript">
  class ModeToggle {
    static get MODE_KEY() {
      return 'mode';
    }
    static get MODE_ATTR() {
      return 'data-mode';
    }
    static get DARK_MODE() {
      return 'dark';
    }
    static get LIGHT_MODE() {
      return 'light';
    }
    static get ID() {
      return 'mode-toggle';
    }

    constructor() {
      if (this.hasMode) {
        if (this.isDarkMode) {
          if (!this.isSysDarkPrefer) {
            this.setDark();
          }
        } else {
          if (this.isSysDarkPrefer) {
            this.setLight();
          }
        }
      }

      let self = this;

      /* always follow the system prefers */
      this.sysDarkPrefers.addEventListener('change', () => {
        if (self.hasMode) {
          if (self.isDarkMode) {
            if (!self.isSysDarkPrefer) {
              self.setDark();
            }
          } else {
            if (self.isSysDarkPrefer) {
              self.setLight();
            }
          }

          self.clearMode();
        }

        self.notify();
      });
    } /* constructor() */

    get sysDarkPrefers() {
      return window.matchMedia('(prefers-color-scheme: dark)');
    }

    get isSysDarkPrefer() {
      return this.sysDarkPrefers.matches;
    }

    get isDarkMode() {
      return this.mode === ModeToggle.DARK_MODE;
    }

    get isLightMode() {
      return this.mode === ModeToggle.LIGHT_MODE;
    }

    get hasMode() {
      return this.mode != null;
    }

    get mode() {
      return sessionStorage.getItem(ModeToggle.MODE_KEY);
    }

    /* get the current mode on screen */
    get modeStatus() {
      if (this.isDarkMode || (!this.hasMode && this.isSysDarkPrefer)) {
        return ModeToggle.DARK_MODE;
      } else {
        return ModeToggle.LIGHT_MODE;
      }
    }

    setDark() {
      document.documentElement.setAttribute(ModeToggle.MODE_ATTR, ModeToggle.DARK_MODE);
      sessionStorage.setItem(ModeToggle.MODE_KEY, ModeToggle.DARK_MODE);
    }

    setLight() {
      document.documentElement.setAttribute(ModeToggle.MODE_ATTR, ModeToggle.LIGHT_MODE);
      sessionStorage.setItem(ModeToggle.MODE_KEY, ModeToggle.LIGHT_MODE);
    }

    clearMode() {
      document.documentElement.removeAttribute(ModeToggle.MODE_ATTR);
      sessionStorage.removeItem(ModeToggle.MODE_KEY);
    }

    /* Notify another plugins that the theme mode has changed */
    notify() {
      window.postMessage(
        {
          direction: ModeToggle.ID,
          message: this.modeStatus
        },
        '*'
      );
    }

    flipMode() {
      if (this.hasMode) {
        if (this.isSysDarkPrefer) {
          if (this.isLightMode) {
            this.clearMode();
          } else {
            this.setLight();
          }
        } else {
          if (this.isDarkMode) {
            this.clearMode();
          } else {
            this.setDark();
          }
        }
      } else {
        if (this.isSysDarkPrefer) {
          this.setLight();
        } else {
          this.setDark();
        }
      }

      this.notify();
    } /* flipMode() */
  } /* ModeToggle */

  const modeToggle = new ModeToggle();
</script>

  

  <!-- A placeholder to allow defining custom metadata -->

</head>


  <body>
    <!-- The Side Bar -->

<aside aria-label="Sidebar" id="sidebar" class="d-flex flex-column align-items-end">
  <header class="profile-wrapper">
    <a href="/" id="avatar" class="rounded-circle">
      
        
        <img src="/assets/img/meow.png" width="112" height="112" alt="avatar" onerror="this.style.display='none'">
      
    </a>

    <h1 class="site-title">
      <a href="/">Yue Lin</a>
    </h1>
    <p class="site-subtitle fst-italic mb-0">Redemption lies within.</p>
  </header>
  <!-- .profile-wrapper -->

  <nav class="flex-column flex-grow-1 w-100 ps-0">
    <ul class="nav">
      <!-- home -->
      <!-- <li class="nav-item">
        <a href="/" class="nav-link">
          <i class="fa-fw fas fa-home"></i>
          <span>HOME</span>
        </a>
      </li> -->
      <!-- the real tabs -->
      
        <li class="nav-item">
          <a href="/categories/" class="nav-link">
            <i class="fa-fw fa-solid fa-chess"></i>
            

            <span>CATEGORIES</span>
          </a>
        </li>
        <!-- .nav-item -->
      
        <li class="nav-item">
          <a href="/archives/" class="nav-link">
            <i class="fa-fw fa-solid fa-scroll"></i>
            

            <span>ARCHIVES</span>
          </a>
        </li>
        <!-- .nav-item -->
      
        <li class="nav-item">
          <a href="/tech/" class="nav-link">
            <i class="fa-fw fa-solid fa-wand-sparkles"></i>
            

            <span>TECH</span>
          </a>
        </li>
        <!-- .nav-item -->
      
        <li class="nav-item">
          <a href="/life/" class="nav-link">
            <i class="fa-fw fa-solid fa-broom"></i>
            

            <span>LIFE</span>
          </a>
        </li>
        <!-- .nav-item -->
      
        <li class="nav-item">
          <a href="/tags/" class="nav-link">
            <i class="fa-fw fa-solid fa-puzzle-piece"></i>
            

            <span>TAGS</span>
          </a>
        </li>
        <!-- .nav-item -->
      
        <li class="nav-item">
          <a href="/about/" class="nav-link">
            <i class="fa-fw fa-solid fa-hat-wizard"></i>
            

            <span>ABOUT</span>
          </a>
        </li>
        <!-- .nav-item -->
      
    </ul>
  </nav>

  <div class="sidebar-bottom d-flex flex-wrap  align-items-center w-100">
    
      <button type="button" class="mode-toggle btn" aria-label="Switch Mode">
        <i class="fas fa-adjust"></i>
      </button>

      
        <span class="icon-border"></span>
      
    

    
      

      
        <a
          href="https://github.com/YueLin301"
          aria-label="github"
          

          
            target="_blank"
            
          

          

          
            rel="noopener noreferrer"
          
        >
          <i class="fab fa-github"></i>
        </a>
      
    
      

      
        <a
          href="https://scholar.google.com/citations?user=fbvQHX4AAAAJ&hl"
          aria-label="google scholar"
          

          
            target="_blank"
            
          

          

          
            rel="noopener noreferrer"
          
        >
          <i class="fas fa-graduation-cap"></i>
        </a>
      
    
      

      
        <a
          href="javascript:location.href = 'mailto:' + ['linyue3h1','gmail.com'].join('@')"
          aria-label="email"
          

          

          

          
        >
          <i class="fas fa-envelope"></i>
        </a>
      
    
  </div>
  <!-- .sidebar-bottom -->
</aside>
<!-- #sidebar -->


    <div id="main-wrapper" class="d-flex justify-content-center">
      <div class="container d-flex flex-column px-xxl-5">
        <!-- The Top Bar -->

<header id="topbar-wrapper" aria-label="Top Bar">
  <div
    id="topbar"
    class="d-flex align-items-center justify-content-between px-lg-3 h-100"
  >
    <nav id="breadcrumb" aria-label="Breadcrumb">
      

      
        
          
            <span>
              <a href="/">
                Home
              </a>
            </span>

          
        
          
        
          
            
              <span>Sequence-to-Sequence Models</span>
            

          
        
      
    </nav>
    <!-- endof #breadcrumb -->

    <button type="button" id="sidebar-trigger" class="btn btn-link">
      <i class="fas fa-bars fa-fw"></i>
    </button>

    <div id="topbar-title">
      Post
    </div>

    <button type="button" id="search-trigger" class="btn btn-link">
      <i class="fas fa-search fa-fw"></i>
    </button>

    <search class="align-items-center ms-3 ms-lg-0">
      <i class="fas fa-search fa-fw"></i>
      <input
        class="form-control"
        id="search-input"
        type="search"
        aria-label="search"
        autocomplete="off"
        placeholder="Search..."
      >
    </search>
    <button type="button" class="btn btn-link text-decoration-none" id="search-cancel">Cancel</button>
  </div>
</header>


        <div class="row flex-grow-1">
          <!-- <main aria-label="Main Content" class="col-12 col-lg-11 col-xl-9 px-md-4"> -->
            <main aria-label="Main Content" class="col-12 col-sm-9 col-lg-9 col-xl-9 px-md-4">
            
              <!-- Refactor the HTML structure -->



<!--
  In order to allow a wide table to scroll horizontally,
  we suround the markdown table with `<div class="table-wrapper">` and `</div>`
-->



<!--
  Fixed kramdown code highlight rendering:
  https://github.com/penibelst/jekyll-compress-html/issues/101
  https://github.com/penibelst/jekyll-compress-html/issues/71#issuecomment-188144901
-->



<!-- Change the icon of checkbox -->



<!-- Handle images -->




  
  

  <!-- CDN URL -->
  

  <!-- Add image path -->
  

  
    
      
      
    

    
    

    

    
    

    
    
    

    
      

      
      
      

      
    
      

      
      
      

      
    
      

      
      
      

      
    
      

      
      
      

      
    

    <!-- take out classes -->
    

    
    

    

    
      
    

    <!-- lazy-load images -->
    

    
      <!-- make sure the `<img>` is wrapped by `<a>` -->
      

      
        <!-- create the image wrapper -->
        

        
        
      
    

    <!-- combine -->
    
  
    

    
    

    

    
    

    
    
    

    
      

      
      
      

      
    
      

      
      
      

      
    
      

      
      
      

      
    
      

      
      
      

      
    

    <!-- take out classes -->
    

    
    

    

    
      
    

    <!-- lazy-load images -->
    

    
      <!-- make sure the `<img>` is wrapped by `<a>` -->
      

      
        <!-- create the image wrapper -->
        

        
        
      
    

    <!-- combine -->
    
  
    

    
    

    

    
    

    
    
    

    
      

      
      
      

      
    
      

      
      
      

      
    
      

      
      
      

      
    
      

      
      
      

      
    

    <!-- take out classes -->
    

    
    

    

    
      
    

    <!-- lazy-load images -->
    

    
      <!-- make sure the `<img>` is wrapped by `<a>` -->
      

      
        <!-- create the image wrapper -->
        

        
        
      
    

    <!-- combine -->
    
  
    

    
    

    

    
    

    
    
    

    
      

      
      
      

      
    
      

      
      
      

      
    
      

      
      
      

      
    
      

      
      
      

      
    

    <!-- take out classes -->
    

    
    

    

    
      
    

    <!-- lazy-load images -->
    

    
      <!-- make sure the `<img>` is wrapped by `<a>` -->
      

      
        <!-- create the image wrapper -->
        

        
        
      
    

    <!-- combine -->
    
  
    

    
    

    

    
    

    
    
    

    
      

      
      
      

      
    
      

      
      
      

      
    
      

      
      
      

      
    
      

      
      
      

      
    

    <!-- take out classes -->
    

    
    

    

    
      
    

    <!-- lazy-load images -->
    

    
      <!-- make sure the `<img>` is wrapped by `<a>` -->
      

      
        <!-- create the image wrapper -->
        

        
        
      
    

    <!-- combine -->
    
  
    

    
    

    

    
    

    
    
    

    
      

      
      
      

      
    
      

      
      
      

      
    
      

      
      
      

      
    
      

      
      
      

      
    

    <!-- take out classes -->
    

    
    

    

    
      
    

    <!-- lazy-load images -->
    

    
      <!-- make sure the `<img>` is wrapped by `<a>` -->
      

      
        <!-- create the image wrapper -->
        

        
        
      
    

    <!-- combine -->
    
  
    

    
    

    

    
    

    
    
    

    
      

      
      
      

      
    
      

      
      
      

      
    
      

      
      
      

      
    
      

      
      
      

      
    

    <!-- take out classes -->
    

    
    

    

    
      
    

    <!-- lazy-load images -->
    

    
      <!-- make sure the `<img>` is wrapped by `<a>` -->
      

      
        <!-- create the image wrapper -->
        

        
        
      
    

    <!-- combine -->
    
  
    

    
    

    

    
    

    
    
    

    
      

      
      
      

      
    
      

      
      
      

      
    
      

      
      
      

      
    
      

      
      
      

      
    

    <!-- take out classes -->
    

    
    

    

    
      
    

    <!-- lazy-load images -->
    

    
      <!-- make sure the `<img>` is wrapped by `<a>` -->
      

      
        <!-- create the image wrapper -->
        

        
        
      
    

    <!-- combine -->
    
  
    

    
    

    

    
    

    
    
    

    
      

      
      
      

      
    
      

      
      
      

      
    
      

      
      
      

      
    
      

      
      
      

      
    

    <!-- take out classes -->
    

    
    

    

    
      
    

    <!-- lazy-load images -->
    

    
      <!-- make sure the `<img>` is wrapped by `<a>` -->
      

      
        <!-- create the image wrapper -->
        

        
        
      
    

    <!-- combine -->
    
  
    

    
    

    

    
    

    
    
    

    
      

      
      
      

      
    
      

      
      
      

      
    
      

      
      
      

      
    
      

      
      
      

      
    

    <!-- take out classes -->
    

    
    

    

    
      
    

    <!-- lazy-load images -->
    

    
      <!-- make sure the `<img>` is wrapped by `<a>` -->
      

      
        <!-- create the image wrapper -->
        

        
        
      
    

    <!-- combine -->
    
  
    

    
    

    

    
    

    
    
    

    
      

      
      
      

      
    
      

      
      
      

      
    
      

      
      
      

      
    
      

      
      
      

      
    

    <!-- take out classes -->
    

    
    

    

    
      
    

    <!-- lazy-load images -->
    

    
      <!-- make sure the `<img>` is wrapped by `<a>` -->
      

      
        <!-- create the image wrapper -->
        

        
        
      
    

    <!-- combine -->
    
  

  


<!-- Add header for code snippets -->



<!-- Create heading anchors -->





  
  

  
    
    

    
      
        
        
      

      
      

      
      
      

      
    
      

      
      

      
      
      

      
    
      

      
      

      
      
      

      
    
      

      
      

      
      
      

      
    
      

      
      

      
      
      

      
    
      

      
      

      
      
      

      
    

    
  

  
  

  
    
    

    
      
        
        
      

      
      

      
      
      

      
    
      

      
      

      
      
      

      
    
      

      
      

      
      
      

      
    
      

      
      

      
      
      

      
    
      

      
      

      
      
      

      
    
      

      
      

      
      
      

      
    
      

      
      

      
      
      

      
    
      

      
      

      
      
      

      
    
      

      
      

      
      
      

      
    
      

      
      

      
      
      

      
    
      

      
      

      
      
      

      
    
      

      
      

      
      
      

      
    
      

      
      

      
      
      

      
    
      

      
      

      
      
      

      
    
      

      
      

      
      
      

      
    

    
  

  
  

  
    
    

    
      
        
        
      

      
      

      
      
      

      
    
      

      
      

      
      
      

      
    
      

      
      

      
      
      

      
    
      

      
      

      
      
      

      
    
      

      
      

      
      
      

      
    
      

      
      

      
      
      

      
    
      

      
      

      
      
      

      
    

    
  

  
  

  




<!-- return -->




<article class="px-1">
  <header>
    <h1 data-toc-skip>Sequence-to-Sequence Models</h1>

    <div class="post-meta text-muted">
      <!-- published date -->
      <span>
        Posted
        <!--
  Date format snippet
  See: ${JS_ROOT}/utils/locale-dateime.js
-->




<time
  
  data-ts="1689446400"
  data-df="ll"
  
    data-bs-toggle="tooltip" data-bs-placement="bottom"
  
>
  Jul 15, 2023
</time>

      </span>

      <!-- lastmod date -->
      
        <span>
          Updated
          <!--
  Date format snippet
  See: ${JS_ROOT}/utils/locale-dateime.js
-->




<time
  
  data-ts="1702993758"
  data-df="ll"
  
    data-bs-toggle="tooltip" data-bs-placement="bottom"
  
>
  Dec 19, 2023
</time>

        </span>
      

      

      <div class="d-flex justify-content-between">
        <!-- author(s) -->
        <span>
          

          By

          <em>
            
              <a href="https://github.com/YueLin301">Yue Lin</a>
            
          </em>
        </span>

        <!-- read time -->
        <!-- Calculate the post's reading time, and display the word count in tooltip -->



<!-- words per minute -->










<!-- return element -->
<span
  class="readtime"
  data-bs-toggle="tooltip"
  data-bs-placement="bottom"
  title="3498 words"
>
  <em>19 min</em> read</span>

      </div>
      <!-- .d-flex -->
    </div>
    <!-- .post-meta -->
  </header>

  <div class="content">
    <h2 id="nlp-terms"><span class="me-2">NLP Terms</span><a href="#nlp-terms" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h2>

<p>NLP = Natural Language Processing</p>

<h3 id="embedding"><span class="me-2">Embedding</span><a href="#embedding" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h3>
<blockquote>
  <p>In a general sense, “embedding” refers to the process of representing one kind of object or data in another space or format. It involves mapping objects from a higher-dimensional space into a lower-dimensional space while preserving certain relationships or properties.</p>

  <p><em>— GPT 3.5</em></p>
</blockquote>

<p>For example, the Principal Component Analysis (PCA) algorithm is an embedding technique. PCA is a widely used dimensionality reduction technique that projects high-dimensional data into a lower-dimensional space, while retaining as much of the data’s variance as possible. In my understanding, the constraint on variance in PCA is intended to allow us to distinguish each point as effectively as possible in the new lower-dimensional space. And that is the “preserved property” in this case.</p>

<p>In NLP, the embedding layer is used to <strong>obtain the feature vector for each token in the input sequence</strong>. One-hot is a simple example of the embedding.</p>

<h4 id="items-to-one-hot-variables"><span class="me-2">Items $\to$ one-hot variables:</span><a href="#items-to-one-hot-variables" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h4>

<div class="language-python highlighter-rouge"><div class="code-header">
        <span data-label-text="Python"><i class="fas fa-code fa-fw small"></i></span>
      <button aria-label="copy" data-title-succeed="Copied!"><i class="far fa-clipboard"></i></button></div><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
</pre></td><td class="rouge-code"><pre><span class="kn">import</span> <span class="n">torch</span>
<span class="kn">import</span> <span class="n">torch.nn.functional</span> <span class="k">as</span> <span class="n">F</span>

<span class="n">A</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="nf">tensor</span><span class="p">([</span><span class="mi">3</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">2</span><span class="p">])</span>
<span class="n">output1</span> <span class="o">=</span> <span class="n">F</span><span class="p">.</span><span class="nf">one_hot</span><span class="p">(</span><span class="n">A</span><span class="p">)</span>
<span class="sh">'''</span><span class="s">
tensor([[0, 0, 0, 1],
        [1, 0, 0, 0],
        [0, 0, 1, 0]])
</span><span class="sh">'''</span>

<span class="n">output2</span> <span class="o">=</span> <span class="n">F</span><span class="p">.</span><span class="nf">one_hot</span><span class="p">(</span><span class="n">A</span><span class="p">,</span> <span class="n">num_classes</span><span class="o">=</span><span class="mi">5</span><span class="p">)</span>
<span class="sh">'''</span><span class="s">
tensor([[0, 0, 0, 1, 0],
        [1, 0, 0, 0, 0],
        [0, 0, 1, 0, 0]])
</span><span class="sh">'''</span>
</pre></td></tr></tbody></table></code></div></div>

<h4 id="items-to-learnable-embedded-variables"><span class="me-2">Items $\to$ learnable embedded variables:</span><a href="#items-to-learnable-embedded-variables" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h4>

<div class="language-python highlighter-rouge"><div class="code-header">
        <span data-label-text="Python"><i class="fas fa-code fa-fw small"></i></span>
      <button aria-label="copy" data-title-succeed="Copied!"><i class="far fa-clipboard"></i></button></div><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
</pre></td><td class="rouge-code"><pre><span class="kn">import</span> <span class="n">torch</span>

<span class="n">torch</span><span class="p">.</span><span class="nf">manual_seed</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>

<span class="n">words</span> <span class="o">=</span> <span class="p">[</span><span class="sh">"</span><span class="s">hello</span><span class="sh">"</span><span class="p">,</span> <span class="sh">"</span><span class="s">world</span><span class="sh">"</span><span class="p">,</span> <span class="sh">"</span><span class="s">haha</span><span class="sh">"</span><span class="p">]</span>
<span class="n">vocab_size</span> <span class="o">=</span> <span class="nf">len</span><span class="p">(</span><span class="n">words</span><span class="p">)</span>
<span class="n">idx</span> <span class="o">=</span> <span class="nf">list</span><span class="p">(</span><span class="nf">range</span><span class="p">(</span><span class="n">vocab_size</span><span class="p">))</span>
<span class="n">dictionary</span> <span class="o">=</span> <span class="nf">dict</span><span class="p">(</span><span class="nf">zip</span><span class="p">(</span><span class="n">words</span><span class="p">,</span> <span class="n">idx</span><span class="p">))</span>  <span class="c1"># {'hello': 0, 'world': 1, 'haha': 2}
</span><span class="n">embedding_dim</span> <span class="o">=</span> <span class="mi">2</span>

<span class="n">embedding_layer</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">nn</span><span class="p">.</span><span class="nc">Embedding</span><span class="p">(</span><span class="n">num_embeddings</span><span class="o">=</span><span class="n">vocab_size</span><span class="p">,</span>     <span class="c1"># how many values in a dim (input)
</span>                                     <span class="n">embedding_dim</span><span class="o">=</span><span class="n">embedding_dim</span><span class="p">)</span>   <span class="c1"># output_dim
</span><span class="nf">print</span><span class="p">(</span><span class="nf">list</span><span class="p">(</span><span class="n">embedding_layer</span><span class="p">.</span><span class="nf">parameters</span><span class="p">()))</span>
<span class="sh">'''</span><span class="s">
[Parameter containing:
tensor([[ 0.6614,  0.2669],
        [ 0.0617,  0.6213],
        [-0.4519, -0.1661]], requires_grad=True)]
</span><span class="sh">'''</span>

<span class="n">lookup_tensor</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="nf">tensor</span><span class="p">([</span><span class="n">dictionary</span><span class="p">[</span><span class="sh">"</span><span class="s">haha</span><span class="sh">"</span><span class="p">]],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="p">.</span><span class="nb">long</span><span class="p">)</span>
<span class="n">haha_embed</span> <span class="o">=</span> <span class="nf">embedding_layer</span><span class="p">(</span><span class="n">lookup_tensor</span><span class="p">)</span>
<span class="nf">print</span><span class="p">(</span><span class="n">haha_embed</span><span class="p">)</span>
<span class="c1"># tensor([[-0.4519, -0.1661]], grad_fn=&lt;EmbeddingBackward0&gt;)
# The result is exactly the third row of the embedding layer parameter matrix.
</span></pre></td></tr></tbody></table></code></div></div>

<p><a href="https://pytorch.org/docs/stable/generated/torch.nn.Embedding.html"><code class="language-plaintext highlighter-rouge">torch.nn.Embedding</code></a>:</p>
<ul>
  <li>Each element in the weight matrix is sampled from $\mathcal{N}(0,1)$.</li>
  <li>“An Embedding layer is essentially just a Linear layer.” (From <a href="https://discuss.pytorch.org/t/how-does-nn-embedding-work/88518/3">this website</a>.)</li>
  <li>The <code class="language-plaintext highlighter-rouge">padding_idx</code> parameter: (<code class="language-plaintext highlighter-rouge">int</code>, optional) - If specified, the entries at padding_idx do not contribute to the gradient.</li>
  <li><code class="language-plaintext highlighter-rouge">PAD_TOKEN</code>, <code class="language-plaintext highlighter-rouge">&lt;BOS&gt;</code> and others should be considered in the <code class="language-plaintext highlighter-rouge">num_embeddings</code> count.</li>
</ul>

<p>Map back:</p>
<ul>
  <li>Given an embedding result $y$, find the corresponding word $x$.</li>
  <li>Calculate the embeddings of all words $(y_1, \ldots, y_n)$,</li>
  <li>$x = \arg\min_i \Vert y - y_i \Vert$</li>
</ul>

<div class="language-python highlighter-rouge"><div class="code-header">
        <span data-label-text="Python"><i class="fas fa-code fa-fw small"></i></span>
      <button aria-label="copy" data-title-succeed="Copied!"><i class="far fa-clipboard"></i></button></div><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
</pre></td><td class="rouge-code"><pre>
<span class="n">all_embeddings</span> <span class="o">=</span> <span class="nf">embedding_layer</span><span class="p">(</span><span class="n">torch</span><span class="p">.</span><span class="nf">arange</span><span class="p">(</span><span class="n">vocab_size</span><span class="p">))</span>
<span class="n">distances</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="nf">norm</span><span class="p">(</span><span class="n">all_embeddings</span> <span class="o">-</span> <span class="n">hello_embed</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="n">min_index</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="nf">argmin</span><span class="p">(</span><span class="n">distances</span><span class="p">).</span><span class="nf">item</span><span class="p">()</span>
<span class="n">closest_word</span> <span class="o">=</span> <span class="p">[</span><span class="n">word</span> <span class="k">for</span> <span class="n">word</span><span class="p">,</span> <span class="n">idx</span> <span class="ow">in</span> <span class="n">dictionary</span><span class="p">.</span><span class="nf">items</span><span class="p">()</span> <span class="k">if</span> <span class="n">idx</span> <span class="o">==</span> <span class="n">min_index</span><span class="p">][</span><span class="mi">0</span><span class="p">]</span>
<span class="nf">print</span><span class="p">(</span><span class="sa">f</span><span class="sh">"</span><span class="s">Closest word for the given vector: </span><span class="si">{</span><span class="n">closest_word</span><span class="si">}</span><span class="sh">"</span><span class="p">)</span>
<span class="c1"># Closest word for the given vector: haha
</span></pre></td></tr></tbody></table></code></div></div>

<h4 id="integer-index-tensors-to-learnable-embedded-variables"><span class="me-2">Integer (index) tensors $\to$ learnable embedded variables:</span><a href="#integer-index-tensors-to-learnable-embedded-variables" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h4>

<div class="language-python highlighter-rouge"><div class="code-header">
        <span data-label-text="Python"><i class="fas fa-code fa-fw small"></i></span>
      <button aria-label="copy" data-title-succeed="Copied!"><i class="far fa-clipboard"></i></button></div><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
</pre></td><td class="rouge-code"><pre><span class="kn">import</span> <span class="n">torch</span>

<span class="n">vocab_size</span> <span class="o">=</span> <span class="mi">10</span>
<span class="n">embedding_dim</span> <span class="o">=</span> <span class="mi">3</span>

<span class="n">embedding_layer</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">nn</span><span class="p">.</span><span class="nc">Embedding</span><span class="p">(</span><span class="n">vocab_size</span><span class="p">,</span> <span class="n">embedding_dim</span><span class="p">)</span>
<span class="nf">print</span><span class="p">(</span><span class="nf">list</span><span class="p">(</span><span class="n">embedding_layer</span><span class="p">.</span><span class="nf">parameters</span><span class="p">()))</span>
<span class="sh">'''</span><span class="s">
tensor([[-2.3097,  2.8327,  0.2768],
        [-1.8660, -0.5876, -0.5116],
        [-0.6474,  0.7756, -0.1920],
        [-1.2533, -0.7186,  1.8712],
        [-1.5365, -1.0957, -0.9209],
        [-0.0757,  2.3399,  0.9409],
        [-0.9143,  1.3293,  0.8625],
        [ 1.3818, -0.1664, -0.5298],
        [ 2.2011, -0.8805,  1.7162],
        [-0.9934,  0.3914,  0.9149]], requires_grad=True)]
</span><span class="sh">'''</span>

<span class="c1"># A batch of 2 samples of 4 indices each
# Each index is in [0, vocab_size - 1]
</span><span class="nb">input</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="nc">LongTensor</span><span class="p">([[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">5</span><span class="p">],</span>     <span class="c1"># Sentence A
</span>                          <span class="p">[</span><span class="mi">4</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">9</span><span class="p">]])</span>    <span class="c1"># Sentence B
</span><span class="n">output</span> <span class="o">=</span> <span class="nf">embedding_layer</span><span class="p">(</span><span class="nb">input</span><span class="p">)</span>
<span class="nf">print</span><span class="p">(</span><span class="n">output</span><span class="p">)</span>
<span class="sh">'''</span><span class="s">
tensor([[[-1.8660, -0.5876, -0.5116],
         [-0.6474,  0.7756, -0.1920],
         [-1.5365, -1.0957, -0.9209],
         [-0.0757,  2.3399,  0.9409]],

        [[-1.5365, -1.0957, -0.9209],
         [-1.2533, -0.7186,  1.8712],
         [-0.6474,  0.7756, -0.1920],
         [-0.9934,  0.3914,  0.9149]]], grad_fn=&lt;EmbeddingBackward0&gt;)
</span><span class="sh">'''</span>
</pre></td></tr></tbody></table></code></div></div>

<h4 id="differentiable-embedding"><span class="me-2">Differentiable embedding</span><a href="#differentiable-embedding" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h4>

<blockquote>
  <p>“An Embedding layer is essentially just a Linear layer.” From <a href="https://discuss.pytorch.org/t/how-does-nn-embedding-work/88518/1">this website</a>.</p>
</blockquote>

<div class="language-python highlighter-rouge"><div class="code-header">
        <span data-label-text="Python"><i class="fas fa-code fa-fw small"></i></span>
      <button aria-label="copy" data-title-succeed="Copied!"><i class="far fa-clipboard"></i></button></div><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
</pre></td><td class="rouge-code"><pre><span class="n">embedding_layer</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">nn</span><span class="p">.</span><span class="nc">Sequential</span><span class="p">(</span>
    <span class="n">torch</span><span class="p">.</span><span class="n">nn</span><span class="p">.</span><span class="nc">Linear</span><span class="p">(</span><span class="n">input_dim</span><span class="p">,</span> <span class="n">output_dim</span><span class="p">,</span> <span class="n">bias</span><span class="o">=</span><span class="bp">False</span><span class="p">),</span>
<span class="p">)</span>
</pre></td></tr></tbody></table></code></div></div>

<h3 id="tokenization"><span class="me-2">Tokenization</span><a href="#tokenization" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h3>

<blockquote class="prompt-info">
  <p>Check <a href="https://neptune.ai/blog/tokenization-in-nlp">this website</a>.</p>
</blockquote>

<div class="language-python highlighter-rouge"><div class="code-header">
        <span data-label-text="Python"><i class="fas fa-code fa-fw small"></i></span>
      <button aria-label="copy" data-title-succeed="Copied!"><i class="far fa-clipboard"></i></button></div><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
9
10
</pre></td><td class="rouge-code"><pre><span class="n">sentence</span> <span class="o">=</span> <span class="sh">'</span><span class="s">We do not see things as they are, we see them as we are.</span><span class="sh">'</span>

<span class="n">character_tokenization</span> <span class="o">=</span> <span class="nf">list</span><span class="p">(</span><span class="n">sentence</span><span class="p">)</span>
<span class="c1"># ['W', 'e', ' ', 'd', 'o', ' ', 'n', 'o', 't', ' ', 's', 'e', 'e', ' ', 't', 'h', 'i', 'n', 'g', 's', ' ', 'a', 's', ' ', 't', 'h', 'e', 'y', ' ', 'a', 'r', 'e', ',', ' ', 'w', 'e', ' ', 's', 'e', 'e', ' ', 't', 'h', 'e', 'm', ' ', 'a', 's', ' ', 'w', 'e', ' ', 'a', 'r', 'e', '.']
</span>
<span class="n">word_tokenization</span> <span class="o">=</span> <span class="n">sentence</span><span class="p">.</span><span class="nf">split</span><span class="p">()</span>
<span class="c1"># ['We', 'do', 'not', 'see', 'things', 'as', 'they', 'are,', 'we', 'see', 'them', 'as', 'we', 'are.']
</span>
<span class="n">sentence_tokenization</span> <span class="o">=</span> <span class="n">sentence</span><span class="p">.</span><span class="nf">split</span><span class="p">(</span><span class="sh">'</span><span class="s">, </span><span class="sh">'</span><span class="p">)</span>
<span class="c1"># ['We do not see things as they are', 'we see them as we are.']
</span></pre></td></tr></tbody></table></code></div></div>

<h3 id="bow"><span class="me-2">BoW</span><a href="#bow" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h3>

<p>BOW = Bag of Words</p>

<p>In my understanding, BoW is a step</p>
<ul>
  <li>to make and clean a word-level tokenization, and</li>
  <li>to count and store the occurrences of each word.</li>
</ul>

<blockquote>
  <p>For instance, given the vocabulary <code class="language-plaintext highlighter-rouge">{apple, banana, cherry}</code>:</p>
  <ul>
    <li>Text: <code class="language-plaintext highlighter-rouge">"apple banana apple"</code></li>
    <li>BoW representation: <code class="language-plaintext highlighter-rouge">{2, 1, 0}</code></li>
  </ul>

  <p><em>— ChatGPT 4</em></p>
</blockquote>

<h3 id="word2vec"><span class="me-2">Word2Vec</span><a href="#word2vec" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h3>

<p>Word2Vec = Word to Vector</p>

<blockquote>
  <p>Word2Vec is a group of related models that are used to produce word embeddings. Word2Vec takes a large corpus of text as its input and produces a high-dimensional space (typically of several hundred dimensions), with each unique word in the corpus being assigned a corresponding vector in the space.</p>

  <p><em>— ChatGPT 4</em></p>
</blockquote>

<p>In my understanding:</p>
<ul>
  <li>During training, the process involves presenting a set of words (the context) and predicting the surrounding words.</li>
  <li>The model learns from reading the corpus to understand the context in which each word occurs in the language.</li>
  <li>If a certain word at a particular position in a context appears frequently in the corpus, then when given that context, the model’s output probability for that word should also be high.</li>
</ul>

<h4 id="cbow"><span class="me-2">CBOW</span><a href="#cbow" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h4>

<p>CBOW = Continuous Bag of Words</p>

<p>The CBOW model predicts the current word based on its context. The objective function to maximize can be expressed as:
\(J(\theta) = \frac{1}{T} \sum_{t=1}^{T} \log p(w_t | C_t)\)</p>

<h4 id="skip-gram"><span class="me-2">Skip-Gram</span><a href="#skip-gram" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h4>

<p>The Skip-Gram model predicts the context given a word. Its objective function can be expressed as:
\(J(\theta) = \frac{1}{T} \sum_{t=1}^{T} \sum_{-c \leq j \leq c, j \neq 0} \log p(w_{t+j} | w_t)\)</p>

<p>Here, $T$ is the total number of words in the training corpus, and $c$ is the size of the context.</p>

<p><a href="https://www.baeldung.com/wp-content/uploads/sites/4/2021/03/Screenshot-2021-03-05-at-11.29.31-1024x616-1.png" class="popup img-link  shimmer"><img src="https://www.baeldung.com/wp-content/uploads/sites/4/2021/03/Screenshot-2021-03-05-at-11.29.31-1024x616-1.png" alt="Skip-Gram-CBOW" width="600" height="600" loading="lazy"></a>
<em>Illustration of CBOW and Skip-Gram from the paper <a href="https://arxiv.org/pdf/1309.4168v1.pdf">“Exploiting Similarities among Languages for Machine Translation”</a>.</em></p>

<h2 id="rnn-models"><span class="me-2">RNN Models</span><a href="#rnn-models" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h2>

<h3 id="rnn"><span class="me-2"><a href="https://d2l.ai/chapter_recurrent-neural-networks/rnn.html">RNN</a></span><a href="#rnn" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h3>

<p>RNN = Recurrent Neural Network</p>

\[\begin{aligned}
    \begin{cases}
      h_t = f_{w_h}(x_t, h_{t-1}) \\
      o_t = g_{w_o}(h_t) \\
    \end{cases}
\end{aligned}\]

<p><a href="https://d2l.ai/_images/rnn-bptt.svg" class="popup img-link  shimmer"><img src="https://d2l.ai/_images/rnn-bptt.svg" alt="RNN" width="500" height="500" loading="lazy"></a>
<em>Illustration of RNN from the book “Dive into Deep Learning”. Boxes represent variables (not shaded) or parameters (shaded) and circles represent operators.</em></p>

<p>If there are $L$ RNN layers, then</p>

\[\begin{aligned}
    \begin{cases}
      h_t^1 = \mathrm{Sigmoid}\left(\mathrm{Linear}(x_t) + \mathrm{Linear}(h_{t-1}^1)\right) \\
      h_t^2 = \mathrm{Sigmoid}\left(\mathrm{Linear}(h_t^1) + \mathrm{Linear}(h_{t-1}^2)\right) \\
      \ldots \\
      o_t = \mathrm{Linear}(h_t^L)
    \end{cases}
\end{aligned}\]

<p><a href="/assets/img/23-07-16-Seq2Seq/stacked-RNN.jpg" class="popup img-link  shimmer"><img src="/assets/img/23-07-16-Seq2Seq/stacked-RNN.jpg" alt="Stacked-RNN" width="500" height="500" loading="lazy"></a>
<em>Illustration of Stacked RNN from the paper <a href="https://www.mdpi.com/1099-4300/25/3/520">“RNNCon: Contribution Coverage Testing for Stacked Recurrent Neural Networks”</a>.</em></p>

<div class="language-python highlighter-rouge"><div class="code-header">
        <span data-label-text="Python"><i class="fas fa-code fa-fw small"></i></span>
      <button aria-label="copy" data-title-succeed="Copied!"><i class="far fa-clipboard"></i></button></div><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
9
10
11
12
13
14
</pre></td><td class="rouge-code"><pre><span class="c1"># Adapted from https://pytorch.org/docs/stable/generated/torch.nn.RNN.html
</span><span class="kn">import</span> <span class="n">torch</span>

<span class="n">rnn</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">nn</span><span class="p">.</span><span class="nc">RNN</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="mi">20</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>   <span class="c1"># input_size, hidden_size, num_layers
</span><span class="nb">input</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="nf">randn</span><span class="p">(</span><span class="mi">5</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">10</span><span class="p">)</span>   <span class="c1"># sequence_length, batch_size, input_size
</span><span class="n">h0</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="nf">randn</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">20</span><span class="p">)</span>      <span class="c1"># num_layers, batch_size, hidden_size
</span><span class="n">output</span><span class="p">,</span> <span class="n">hn</span> <span class="o">=</span> <span class="nf">rnn</span><span class="p">(</span><span class="nb">input</span><span class="p">,</span> <span class="n">h0</span><span class="p">)</span>     <span class="c1"># h0: Defaults to zeros if not provided.
</span>
<span class="nf">print</span><span class="p">(</span><span class="n">output</span><span class="p">.</span><span class="nf">size</span><span class="p">(),</span> <span class="n">hn</span><span class="p">.</span><span class="nf">size</span><span class="p">())</span>
<span class="c1"># torch.Size([5, 3, 20]) torch.Size([2, 3, 20])
# output size: sequence_length, batch_size, hidden_size
</span>
<span class="c1"># If parameter batch_first=True,
# then the first parameter should be the batch_size.
</span></pre></td></tr></tbody></table></code></div></div>

<p>In NLP:</p>
<ul>
  <li>An input is a sentence. The <code class="language-plaintext highlighter-rouge">sequence_length</code> is the number of words in the sentence.</li>
  <li>The <code class="language-plaintext highlighter-rouge">input_size</code> is the embedding dimension of each word.</li>
  <li>The <code class="language-plaintext highlighter-rouge">output_size</code> equals the <code class="language-plaintext highlighter-rouge">sequence_length</code>.</li>
  <li>All the hidden states have the same <code class="language-plaintext highlighter-rouge">hidden_size</code>.</li>
</ul>

<p>An example that makes it easy to remember the dimensions of various quantities:</p>

<div class="language-python highlighter-rouge"><div class="code-header">
        <span data-label-text="Python"><i class="fas fa-code fa-fw small"></i></span>
      <button aria-label="copy" data-title-succeed="Copied!"><i class="far fa-clipboard"></i></button></div><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
</pre></td><td class="rouge-code"><pre><span class="c1"># input_size = embedding_dim = 3
</span><span class="n">embedded_words</span> <span class="o">=</span> <span class="p">{</span><span class="sh">"</span><span class="s">I</span><span class="sh">"</span><span class="p">:</span> <span class="p">[</span><span class="mf">0.3</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">,</span> <span class="mf">0.1</span><span class="p">],</span>
                  <span class="sh">"</span><span class="s">am</span><span class="sh">"</span><span class="p">:</span> <span class="p">[</span><span class="mf">0.4</span><span class="p">,</span> <span class="mf">0.4</span><span class="p">,</span> <span class="mf">0.3</span><span class="p">],</span>
                  <span class="sh">"</span><span class="s">so</span><span class="sh">"</span><span class="p">:</span> <span class="p">[</span><span class="mf">0.1</span><span class="p">,</span> <span class="mf">0.9</span><span class="p">,</span> <span class="mf">0.2</span><span class="p">],</span>
                  <span class="sh">"</span><span class="s">happy</span><span class="sh">"</span><span class="p">:</span> <span class="p">[</span><span class="mf">0.5</span><span class="p">,</span> <span class="mf">0.3</span><span class="p">,</span> <span class="mf">0.8</span><span class="p">],</span>
                  <span class="sh">"</span><span class="s">sad</span><span class="sh">"</span><span class="p">:</span> <span class="p">[</span><span class="mf">0.2</span><span class="p">,</span> <span class="mf">0.6</span><span class="p">,</span> <span class="mf">0.1</span><span class="p">],</span>
                  <span class="sh">"</span><span class="s">.</span><span class="sh">"</span><span class="p">:</span> <span class="p">[</span><span class="mf">0.6</span><span class="p">,</span> <span class="mf">0.2</span><span class="p">,</span> <span class="mf">0.6</span><span class="p">],</span>
                  <span class="sh">"</span><span class="s">&lt;EOS&gt;</span><span class="sh">"</span><span class="p">:</span> <span class="p">[</span><span class="mf">0.0</span><span class="p">,</span> <span class="mf">0.0</span><span class="p">,</span> <span class="mf">0.0</span><span class="p">],</span>
                  <span class="sh">"</span><span class="s">&lt;PAD&gt;</span><span class="sh">"</span><span class="p">:</span> <span class="p">[</span><span class="mf">0.9</span><span class="p">,</span> <span class="mf">0.9</span><span class="p">,</span> <span class="mf">0.9</span><span class="p">]}</span>

<span class="n">sentences</span> <span class="o">=</span> <span class="p">[</span><span class="sh">"</span><span class="s">I am so happy.</span><span class="sh">"</span><span class="p">,</span>
             <span class="sh">"</span><span class="s">I am sad.</span><span class="sh">"</span><span class="p">]</span>

<span class="c1"># dataset_size = (batch_size, sequence_length, embedding_dim) = (2, 6, 3,)
# sequence_length = max(sentence_length); Padding
</span><span class="n">embedded_sentences</span> <span class="o">=</span> <span class="p">[[[</span><span class="mf">0.3</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">,</span> <span class="mf">0.1</span><span class="p">],</span>
                       <span class="p">[</span><span class="mf">0.4</span><span class="p">,</span> <span class="mf">0.4</span><span class="p">,</span> <span class="mf">0.3</span><span class="p">],</span>
                       <span class="p">[</span><span class="mf">0.1</span><span class="p">,</span> <span class="mf">0.9</span><span class="p">,</span> <span class="mf">0.2</span><span class="p">],</span>
                       <span class="p">[</span><span class="mf">0.5</span><span class="p">,</span> <span class="mf">0.3</span><span class="p">,</span> <span class="mf">0.8</span><span class="p">],</span>
                       <span class="p">[</span><span class="mf">0.2</span><span class="p">,</span> <span class="mf">0.6</span><span class="p">,</span> <span class="mf">0.1</span><span class="p">],</span>
                       <span class="p">[</span><span class="mf">0.0</span><span class="p">,</span> <span class="mf">0.0</span><span class="p">,</span> <span class="mf">0.0</span><span class="p">]],</span>

                      <span class="p">[[</span><span class="mf">0.3</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">,</span> <span class="mf">0.1</span><span class="p">],</span>
                       <span class="p">[</span><span class="mf">0.4</span><span class="p">,</span> <span class="mf">0.4</span><span class="p">,</span> <span class="mf">0.3</span><span class="p">],</span>
                       <span class="p">[</span><span class="mf">0.5</span><span class="p">,</span> <span class="mf">0.3</span><span class="p">,</span> <span class="mf">0.8</span><span class="p">],</span>
                       <span class="p">[</span><span class="mf">0.6</span><span class="p">,</span> <span class="mf">0.2</span><span class="p">,</span> <span class="mf">0.6</span><span class="p">],</span>
                       <span class="p">[</span><span class="mf">0.0</span><span class="p">,</span> <span class="mf">0.0</span><span class="p">,</span> <span class="mf">0.0</span><span class="p">],</span>
                       <span class="p">[</span><span class="mf">0.9</span><span class="p">,</span> <span class="mf">0.9</span><span class="p">,</span> <span class="mf">0.9</span><span class="p">]]]</span>

<span class="c1"># hidden_size, num_layers: determined by parameter tuning :)
</span></pre></td></tr></tbody></table></code></div></div>

<h3 id="bptt"><span class="me-2"><a href="https://d2l.ai/chapter_recurrent-neural-networks/bptt.html">BPTT</a></span><a href="#bptt" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h3>

<p>BPTT = Backpropagation Through Time</p>

<p>\(L = \frac{1}{T}\sum\limits_{t} l(o_t,y_t)\)<br />
\(\begin{aligned}
    \frac{\partial L}{\partial w_o} =&amp; \frac{1}{T}\sum\limits_{t} \frac{\partial l(y_t,o_t)}{\partial w_o} \\
    =&amp; \frac{1}{T}\sum\limits_{t}
    \frac{\partial l(y_t,o_t)}{\partial o_t}\cdot
     \frac{\partial o_t}{\partial w_o}
\end{aligned}\)<br />
\(\begin{aligned}
    \frac{\partial L}{\partial w_h} =&amp; \frac{1}{T}\sum\limits_{t} \frac{\partial l(y_t,o_t)}{\partial w_h} \\
    =&amp; \frac{1}{T}\sum\limits_{t} \frac{\partial l(y_t,o_t)}{\partial o_t} \cdot
     \frac{\partial o_t}{\partial h_t} \cdot
      \textcolor{red}{\frac{\partial h_t}{\partial w_h}}
\end{aligned}\)</p>

\[\begin{aligned}
    \textcolor{red}{\frac{\partial h_t}{\partial w_h}} =&amp;
    \frac{\partial f(x_t, h_{t-1}, w_h)}{\partial w_h} + \frac{\partial f(x_t, h_{t-1}, w_h)}{\partial h_{t-1}} \cdot 
    \textcolor{red}{\frac{\partial h_{t-1}}{\partial w_h}}
\end{aligned}\]

\[\begin{cases}
      z_0 = a_0 = 0 \\
      z_k = a_k + b_k \cdot z_{k-1} \\
\end{cases}\]

\[\begin{aligned}
    z_k = a_k + \sum\limits_{i=0}^{k-1}
        \left(\prod\limits_{j=i+1}^k b_j \right) \cdot a_i
\end{aligned}\]

<h3 id="lstm"><span class="me-2"><a href="https://d2l.ai/chapter_recurrent-modern/lstm.html">LSTM</a></span><a href="#lstm" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h3>

<p>LSTM = Long Short-Term Memory</p>

<ul>
  <li>To learn long-term dependencies (owing to vanishing and exploding gradients).</li>
  <li>In my understanding, there are two kinds of hidden states, $\mathrm{c}$ and $\mathrm{h}$. And $\mathrm{c}$ is renamed as the <strong>memory cell internal state</strong>.</li>
</ul>

<p>Each layer is like:</p>

\[\begin{aligned}
  \begin{cases}
      i_t =&amp; \mathrm{Sigmoid}\left(\mathrm{Linear}(x_t) + \mathrm{Linear}(h_{t-1})\right) \\
      f_t =&amp; \mathrm{Sigmoid}\left(\mathrm{Linear}(x_t) + \mathrm{Linear}(h_{t-1})\right) \\
      g_t =&amp; \mathrm{tanh}\left(\mathrm{Linear}(x_t) + \mathrm{Linear}(h_{t-1})\right) \\
      o_t =&amp; \mathrm{Sigmoid}\left(\mathrm{Linear}(x_t) + \mathrm{Linear}(h_{t-1})\right) \\
      c_t =&amp; f_t \odot c_{t-1} + i_t \odot g_t \\
      h_t =&amp; o_t \odot \mathrm{tanh}(c_t)
  \end{cases}
\end{aligned}\]

<blockquote class="prompt-info">
  <p>Adapted from <a href="https://pytorch.org/docs/stable/generated/torch.nn.LSTM.html">the PyTorch document</a>.</p>
</blockquote>

<ul>
  <li>$h_t$: the hidden state.</li>
  <li>$c_t$: the cell state.</li>
  <li>$i_t$: the input gate.</li>
  <li>$f_t$: the forget gate.</li>
  <li>$g_t$: the cell gate.</li>
  <li>$o_t$: the output gate.</li>
  <li>All values of the three gates are in the range of $(0, 1)$ because of the sigmoid function.</li>
  <li>$g_t$ is the vanilla part of an RNN, and it indicates the information that we currently get.</li>
  <li>$i_t$ controls how much we cares about the current information.</li>
  <li>$c$ is an addtional hidden state channel, and it also indicates the memory.</li>
  <li>$f_t$ controls how much we cares about the memory.</li>
  <li>$c_t$ and $h_t$ do not impact the curren output $o_t$.</li>
</ul>

<p><a href="https://d2l.ai/_images/lstm-3.svg" class="popup img-link  shimmer"><img src="https://d2l.ai/_images/lstm-3.svg" alt="LSTM" width="700" height="700" loading="lazy"></a>
<em>Illustration of LSTM from the book “Dive into Deep Learning”.</em></p>

<div class="language-python highlighter-rouge"><div class="code-header">
        <span data-label-text="Python"><i class="fas fa-code fa-fw small"></i></span>
      <button aria-label="copy" data-title-succeed="Copied!"><i class="far fa-clipboard"></i></button></div><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
</pre></td><td class="rouge-code"><pre><span class="c1"># Adapted from https://pytorch.org/docs/stable/generated/torch.nn.LSTM.html
</span><span class="kn">import</span> <span class="n">torch</span>

<span class="n">rnn</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">nn</span><span class="p">.</span><span class="nc">LSTM</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="mi">20</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>    <span class="c1"># input_size, hidden_size, num_layers
</span><span class="nb">input</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="nf">randn</span><span class="p">(</span><span class="mi">5</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">10</span><span class="p">)</span>     <span class="c1"># sequence_length, batch_size, input_size
</span><span class="n">h0</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="nf">randn</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">20</span><span class="p">)</span>        <span class="c1"># num_layers, batch_size, hidden_size
</span><span class="n">c0</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="nf">randn</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">20</span><span class="p">)</span>        <span class="c1"># num_layers, batch_size, hidden_size
</span><span class="n">output</span><span class="p">,</span> <span class="p">(</span><span class="n">hn</span><span class="p">,</span> <span class="n">cn</span><span class="p">)</span> <span class="o">=</span> <span class="nf">rnn</span><span class="p">(</span><span class="nb">input</span><span class="p">,</span> <span class="p">(</span><span class="n">h0</span><span class="p">,</span> <span class="n">c0</span><span class="p">))</span> <span class="c1"># h0: Defaults to zeros if not provided.
</span>
<span class="nf">print</span><span class="p">(</span><span class="n">output</span><span class="p">.</span><span class="nf">size</span><span class="p">(),</span> <span class="n">hn</span><span class="p">.</span><span class="nf">size</span><span class="p">(),</span> <span class="n">cn</span><span class="p">.</span><span class="nf">size</span><span class="p">())</span>
<span class="c1"># torch.Size([5, 3, 20]) torch.Size([2, 3, 20]) torch.Size([2, 3, 20])
# output size: sequence_length, batch_size, hidden_size
</span>
<span class="c1"># If parameter batch_first=True,
# then the first parameter should be the batch_size.
</span></pre></td></tr></tbody></table></code></div></div>

<h3 id="gru"><span class="me-2"><a href="https://d2l.ai/chapter_recurrent-modern/gru.html">GRU</a></span><a href="#gru" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h3>

<p>GRU = Gated Recurrent Units</p>

<p>Each layer is like:</p>

\[\begin{aligned}
  \begin{cases}
      r_t =&amp; \mathrm{Sigmoid}\left(\mathrm{Linear}(x_t) + \mathrm{Linear}(h_{t-1})\right) \\
      z_t =&amp; \mathrm{Sigmoid}\left(\mathrm{Linear}(x_t) + \mathrm{Linear}(h_{t-1})\right) \\
      n_t =&amp; \mathrm{tanh}\left(\mathrm{Linear}(x_t) + r_t \odot \mathrm{Linear}(h_{t-1})\right) \\
      h_t =&amp; (1-z_t)\odot n_t + z \odot h_{t-1}
  \end{cases}
\end{aligned}\]

<ul>
  <li>$h_t$: the hidden state. It can be used as the output.</li>
  <li>$r_t$: the reset gate, controls how much we cares about the memory. It is a bit like the forget gate $f_t$ in LSTM</li>
  <li>$z_t$: the update gate, controls how much we cares about the current information. It is a bit like the input gate $i_t$ in LSTM.</li>
  <li>$n_t$: the candidate hidden state, or the new gate.
    <ul>
      <li>If the reset gate $r_t$ is close to $1$, then it is like the vanilla RNN.</li>
      <li>If the reset gate $r_t$ is close to $0$, then the new gate $n_t$ is the result of an MLP of $x_t$.</li>
    </ul>
  </li>
</ul>

<p><a href="https://d2l.ai/_images/gru-3.svg" class="popup img-link  shimmer"><img src="https://d2l.ai/_images/gru-3.svg" alt="GRU" width="700" height="700" loading="lazy"></a>
<em>Illustration of GRU from the book “Dive into Deep Learning”.</em></p>

<div class="language-python highlighter-rouge"><div class="code-header">
        <span data-label-text="Python"><i class="fas fa-code fa-fw small"></i></span>
      <button aria-label="copy" data-title-succeed="Copied!"><i class="far fa-clipboard"></i></button></div><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
9
10
11
12
13
14
</pre></td><td class="rouge-code"><pre><span class="c1"># Adapted from https://pytorch.org/docs/stable/generated/torch.nn.GRU.html
</span><span class="kn">import</span> <span class="n">torch</span>

<span class="n">rnn</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">nn</span><span class="p">.</span><span class="nc">GRU</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="mi">20</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>   <span class="c1"># input_size, hidden_size, num_layers
</span><span class="nb">input</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="nf">randn</span><span class="p">(</span><span class="mi">5</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">10</span><span class="p">)</span>   <span class="c1"># sequence_length, batch_size, input_size
</span><span class="n">h0</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="nf">randn</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">20</span><span class="p">)</span>      <span class="c1"># num_layers, batch_size, hidden_size
</span><span class="n">output</span><span class="p">,</span> <span class="n">hn</span> <span class="o">=</span> <span class="nf">rnn</span><span class="p">(</span><span class="nb">input</span><span class="p">,</span> <span class="n">h0</span><span class="p">)</span>     <span class="c1"># h0: Defaults to zeros if not provided.
</span>
<span class="nf">print</span><span class="p">(</span><span class="n">output</span><span class="p">.</span><span class="nf">size</span><span class="p">(),</span> <span class="n">hn</span><span class="p">.</span><span class="nf">size</span><span class="p">())</span>
<span class="c1"># torch.Size([5, 3, 20]) torch.Size([2, 3, 20])
# output size: sequence_length, batch_size, hidden_size
</span>
<span class="c1"># If parameter batch_first=True,
# then the first parameter should be the batch_size.
</span></pre></td></tr></tbody></table></code></div></div>

<hr />

<h2 id="encoder-decoder"><span class="me-2"><a href="https://d2l.ai/chapter_recurrent-modern/seq2seq.html">Encoder-Decoder</a></span><a href="#encoder-decoder" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h2>

<h3 id="variable-length-inputs"><span class="me-2">Variable-length inputs</span><a href="#variable-length-inputs" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h3>

<ul>
  <li>Truncation and Padding
    <ul>
      <li><a href="https://d2l.ai/chapter_recurrent-modern/machine-translation-and-dataset.html#loading-sequences-of-fixed-length">Dive Into Deep Learning 10.5.3</a></li>
    </ul>
  </li>
  <li>Relation Network
    <ul>
      <li><a href="https://medium.com/@andre.holzner/learning-a-function-with-a-variable-number-of-inputs-with-pytorch-c487e35d4dba">A blog</a></li>
      <li><a href="https://arxiv.org/pdf/1702.05068.pdf">ICLR 2017</a></li>
    </ul>
  </li>
  <li>Embedding.</li>
  <li><strong>Encoder-decoder.</strong></li>
</ul>

<blockquote>
  <p>In general sequence-to-sequence problems like machine translation (Section 10.5), inputs and outputs are of varying lengths that are unaligned. The <strong>standard</strong> approach to handling this sort of data is to design an encoder–decoder architecture (Fig. 10.6.1) … <em>— Dive into Deep Learning.</em></p>
</blockquote>

<h3 id="the-structure"><span class="me-2">The structure</span><a href="#the-structure" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h3>

<p><a href="https://d2l.ai/_images/encoder-decoder.svg" class="popup img-link  shimmer"><img src="https://d2l.ai/_images/encoder-decoder.svg" alt="Encoder-Decoder" width="600" height="600" loading="lazy"></a>
<em>Illustration of the encoder-decoder architecture from the book “Dive into Deep Learning”.</em></p>

<ul>
  <li>Encoder: <code class="language-plaintext highlighter-rouge">"Hello, world."</code> $\to$ a hidden state (or context variable) of fixed-shape.</li>
  <li>Decoder 1: the state $\to$ <code class="language-plaintext highlighter-rouge">"你好，世界。"</code></li>
  <li>Decoder 2: the state $\to$ <code class="language-plaintext highlighter-rouge">"Hola mundo"</code></li>
</ul>

<p><a href="https://d2l.ai/_images/seq2seq.svg" class="popup img-link  shimmer"><img src="https://d2l.ai/_images/seq2seq.svg" alt="Encoder-Decoder-Teacher-Forcing" width="700" height="700" loading="lazy"></a>
<em>Illustration of the encoder-decoder architecture (teacher forcing) from the book “Dive into Deep Learning”.</em></p>

<p><a href="https://d2l.ai/_images/seq2seq-predict.svg" class="popup img-link  shimmer"><img src="https://d2l.ai/_images/seq2seq-predict.svg" alt="Encoder-Decoder-Prediction" width="700" height="700" loading="lazy"></a>
<em>Illustration of the encoder-decoder architecture (prediction) from the book “Dive into Deep Learning”.</em></p>

<p>The encoder and the decoder are usually RNNs.</p>
<ul>
  <li><code class="language-plaintext highlighter-rouge">&lt;eos&gt;</code> means the end of the sequence.
    <ul>
      <li>Inputting <code class="language-plaintext highlighter-rouge">&lt;eos&gt;</code> into the encoder indicates the end of this sentence.</li>
      <li>In prediction: When the decoder outputs <code class="language-plaintext highlighter-rouge">&lt;eos&gt;</code>, it will automatically stop and no longer continue generating output.</li>
    </ul>
  </li>
  <li><code class="language-plaintext highlighter-rouge">&lt;bos&gt;</code> means the beginning of the sequence, used to signal the decoder when to begin generating a new sequence.</li>
  <li>The input of the encoder is a variable-length sequence, but its output is of fixed-length, named as the state or the context variable $c$.</li>
  <li>$c = q(h_1, \ldots, h_t)$, where $q$ is a customized function. In the figures, $c = h_t$.</li>
  <li>The context variable will be fed into the decoder at evry time step or at the first time step.</li>
  <li>Teacher Forcing: The input of the decoder is <code class="language-plaintext highlighter-rouge">(&lt;bos&gt;, sequence)</code>, and the target is <code class="language-plaintext highlighter-rouge">(sequence, &lt;eos&gt;)</code>.</li>
  <li>Prediction: The input of the decoder at every time step is the output from the previous time step.</li>
  <li>When calculating the loss, the padding tokens are masked.</li>
</ul>

<p><a href="https://d2l.ai/_images/seq2seq-details.svg" class="popup img-link  shimmer"><img src="https://d2l.ai/_images/seq2seq-details.svg" alt="Encoder-Decoder" width="500" height="500" loading="lazy"></a>
<em>Illustration of the encoder-decoder architecture where the RNNs are stacked, from the book “Dive into Deep Learning”.</em></p>

<h3 id="teacher-forcing"><span class="me-2">Teacher forcing</span><a href="#teacher-forcing" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h3>

<p>Teacher Forcing: The input of the decoder is <code class="language-plaintext highlighter-rouge">(&lt;bos&gt;, sequence)</code>, and the target is <code class="language-plaintext highlighter-rouge">(sequence, &lt;eos&gt;)</code>.</p>

<blockquote>
  <p>Without using teacher forcing, the model at each timestep would receive the output from the previous timestep and use this output to predict the next timestep. However, this approach has an inherent problem: early in training, the model is likely to produce incorrect predictions, leading the next timestep prediction to be based on this incorrect output. Such mistakes can accumulate in subsequent timesteps.</p>

  <p>To combat this, the Teacher Forcing technique is introduced during training. Specifically, instead of the model receiving its prediction from the previous timestep, it directly receives the actual output from the previous timestep. In this way, even if the model makes an error at a particular timestep, it can continue making predictions based on the actual data, preventing error accumulation.</p>

  <p><em>— ChatGPT 4</em></p>
</blockquote>

<h3 id="code"><span class="me-2">Code</span><a href="#code" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h3>

<div class="language-python highlighter-rouge"><div class="code-header">
        <span data-label-text="Python"><i class="fas fa-code fa-fw small"></i></span>
      <button aria-label="copy" data-title-succeed="Copied!"><i class="far fa-clipboard"></i></button></div><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57
58
59
60
61
62
63
64
65
66
67
68
69
70
71
72
73
74
75
76
77
78
79
80
81
82
83
84
85
86
87
88
89
90
91
92
93
94
95
96
97
98
99
100
101
102
103
104
105
106
107
108
109
110
111
112
113
114
115
116
117
118
119
120
121
122
123
124
125
126
127
128
129
130
131
132
133
134
135
136
137
138
139
140
</pre></td><td class="rouge-code"><pre><span class="c1"># Generated by ChatGPT 4
</span>
<span class="kn">import</span> <span class="n">torch</span>
<span class="kn">import</span> <span class="n">torch.nn</span> <span class="k">as</span> <span class="n">nn</span>
<span class="kn">import</span> <span class="n">torch.optim</span> <span class="k">as</span> <span class="n">optim</span>


<span class="k">class</span> <span class="nc">Encoder</span><span class="p">(</span><span class="n">nn</span><span class="p">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">input_dim</span><span class="p">,</span> <span class="n">emb_dim</span><span class="p">,</span> <span class="n">hidden_dim</span><span class="p">,</span> <span class="n">n_layers</span><span class="p">,</span> <span class="n">dropout</span><span class="p">):</span>
        <span class="nf">super</span><span class="p">().</span><span class="nf">__init__</span><span class="p">()</span>
        <span class="n">self</span><span class="p">.</span><span class="n">embedding</span> <span class="o">=</span> <span class="n">nn</span><span class="p">.</span><span class="nc">Embedding</span><span class="p">(</span><span class="n">input_dim</span><span class="p">,</span> <span class="n">emb_dim</span><span class="p">)</span>
        <span class="n">self</span><span class="p">.</span><span class="n">rnn</span> <span class="o">=</span> <span class="n">nn</span><span class="p">.</span><span class="nc">RNN</span><span class="p">(</span><span class="n">emb_dim</span><span class="p">,</span> <span class="n">hidden_dim</span><span class="p">,</span> <span class="n">n_layers</span><span class="p">,</span> <span class="n">dropout</span><span class="o">=</span><span class="n">dropout</span><span class="p">)</span>
        <span class="n">self</span><span class="p">.</span><span class="n">dropout</span> <span class="o">=</span> <span class="n">nn</span><span class="p">.</span><span class="nc">Dropout</span><span class="p">(</span><span class="n">dropout</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">src</span><span class="p">):</span>
        <span class="n">embedded</span> <span class="o">=</span> <span class="n">self</span><span class="p">.</span><span class="nf">dropout</span><span class="p">(</span><span class="n">self</span><span class="p">.</span><span class="nf">embedding</span><span class="p">(</span><span class="n">src</span><span class="p">))</span>
        <span class="n">outputs</span><span class="p">,</span> <span class="n">hidden</span> <span class="o">=</span> <span class="n">self</span><span class="p">.</span><span class="nf">rnn</span><span class="p">(</span><span class="n">embedded</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">hidden</span>


<span class="k">class</span> <span class="nc">Decoder</span><span class="p">(</span><span class="n">nn</span><span class="p">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">output_dim</span><span class="p">,</span> <span class="n">emb_dim</span><span class="p">,</span> <span class="n">hidden_dim</span><span class="p">,</span> <span class="n">n_layers</span><span class="p">,</span> <span class="n">dropout</span><span class="p">):</span>
        <span class="nf">super</span><span class="p">().</span><span class="nf">__init__</span><span class="p">()</span>
        <span class="n">self</span><span class="p">.</span><span class="n">output_dim</span> <span class="o">=</span> <span class="n">output_dim</span>
        <span class="n">self</span><span class="p">.</span><span class="n">embedding</span> <span class="o">=</span> <span class="n">nn</span><span class="p">.</span><span class="nc">Embedding</span><span class="p">(</span><span class="n">output_dim</span><span class="p">,</span> <span class="n">emb_dim</span><span class="p">)</span>
        <span class="n">self</span><span class="p">.</span><span class="n">rnn</span> <span class="o">=</span> <span class="n">nn</span><span class="p">.</span><span class="nc">RNN</span><span class="p">(</span><span class="n">emb_dim</span><span class="p">,</span> <span class="n">hidden_dim</span><span class="p">,</span> <span class="n">n_layers</span><span class="p">,</span> <span class="n">dropout</span><span class="o">=</span><span class="n">dropout</span><span class="p">)</span>
        <span class="n">self</span><span class="p">.</span><span class="n">fc_out</span> <span class="o">=</span> <span class="n">nn</span><span class="p">.</span><span class="nc">Linear</span><span class="p">(</span><span class="n">hidden_dim</span><span class="p">,</span> <span class="n">output_dim</span><span class="p">)</span>
        <span class="n">self</span><span class="p">.</span><span class="n">dropout</span> <span class="o">=</span> <span class="n">nn</span><span class="p">.</span><span class="nc">Dropout</span><span class="p">(</span><span class="n">dropout</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="nb">input</span><span class="p">,</span> <span class="n">hidden</span><span class="p">):</span>
        <span class="nb">input</span> <span class="o">=</span> <span class="nb">input</span><span class="p">.</span><span class="nf">unsqueeze</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
        <span class="n">embedded</span> <span class="o">=</span> <span class="n">self</span><span class="p">.</span><span class="nf">dropout</span><span class="p">(</span><span class="n">self</span><span class="p">.</span><span class="nf">embedding</span><span class="p">(</span><span class="nb">input</span><span class="p">))</span>
        <span class="n">output</span><span class="p">,</span> <span class="n">hidden</span> <span class="o">=</span> <span class="n">self</span><span class="p">.</span><span class="nf">rnn</span><span class="p">(</span><span class="n">embedded</span><span class="p">,</span> <span class="n">hidden</span><span class="p">)</span>
        <span class="n">prediction</span> <span class="o">=</span> <span class="n">self</span><span class="p">.</span><span class="nf">fc_out</span><span class="p">(</span><span class="n">output</span><span class="p">.</span><span class="nf">squeeze</span><span class="p">(</span><span class="mi">0</span><span class="p">))</span>
        <span class="k">return</span> <span class="n">prediction</span><span class="p">,</span> <span class="n">hidden</span>


<span class="k">class</span> <span class="nc">Seq2Seq</span><span class="p">(</span><span class="n">nn</span><span class="p">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">encoder</span><span class="p">,</span> <span class="n">decoder</span><span class="p">,</span> <span class="n">device</span><span class="p">):</span>
        <span class="nf">super</span><span class="p">().</span><span class="nf">__init__</span><span class="p">()</span>
        <span class="n">self</span><span class="p">.</span><span class="n">encoder</span> <span class="o">=</span> <span class="n">encoder</span>
        <span class="n">self</span><span class="p">.</span><span class="n">decoder</span> <span class="o">=</span> <span class="n">decoder</span>
        <span class="n">self</span><span class="p">.</span><span class="n">device</span> <span class="o">=</span> <span class="n">device</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">src</span><span class="p">,</span> <span class="n">trg</span><span class="p">,</span> <span class="n">teacher_forcing_ratio</span><span class="o">=</span><span class="mf">0.5</span><span class="p">):</span>
        <span class="n">trg_len</span> <span class="o">=</span> <span class="n">trg</span><span class="p">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
        <span class="n">batch_size</span> <span class="o">=</span> <span class="n">trg</span><span class="p">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>
        <span class="n">trg_vocab_size</span> <span class="o">=</span> <span class="n">self</span><span class="p">.</span><span class="n">decoder</span><span class="p">.</span><span class="n">output_dim</span>
        <span class="n">outputs</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="nf">zeros</span><span class="p">(</span><span class="n">trg_len</span><span class="p">,</span> <span class="n">batch_size</span><span class="p">,</span> <span class="n">trg_vocab_size</span><span class="p">).</span><span class="nf">to</span><span class="p">(</span><span class="n">self</span><span class="p">.</span><span class="n">device</span><span class="p">)</span>
        <span class="n">hidden</span> <span class="o">=</span> <span class="n">self</span><span class="p">.</span><span class="nf">encoder</span><span class="p">(</span><span class="n">src</span><span class="p">)</span>
        <span class="nb">input</span> <span class="o">=</span> <span class="n">trg</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="p">:]</span>
        <span class="k">for</span> <span class="n">t</span> <span class="ow">in</span> <span class="nf">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">trg_len</span><span class="p">):</span>
            <span class="n">output</span><span class="p">,</span> <span class="n">hidden</span> <span class="o">=</span> <span class="n">self</span><span class="p">.</span><span class="nf">decoder</span><span class="p">(</span><span class="nb">input</span><span class="p">,</span> <span class="n">hidden</span><span class="p">)</span>
            <span class="n">outputs</span><span class="p">[</span><span class="n">t</span><span class="p">]</span> <span class="o">=</span> <span class="n">output</span>
            <span class="n">teacher_force</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="nf">rand</span><span class="p">(</span><span class="mi">1</span><span class="p">).</span><span class="nf">item</span><span class="p">()</span> <span class="o">&lt;</span> <span class="n">teacher_forcing_ratio</span>
            <span class="n">top1</span> <span class="o">=</span> <span class="n">output</span><span class="p">.</span><span class="nf">argmax</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>
            <span class="nb">input</span> <span class="o">=</span> <span class="n">trg</span><span class="p">[</span><span class="n">t</span><span class="p">]</span> <span class="k">if</span> <span class="n">teacher_force</span> <span class="k">else</span> <span class="n">top1</span>
        <span class="k">return</span> <span class="n">outputs</span>


<span class="n">INPUT_DIM</span> <span class="o">=</span> <span class="mi">1000</span>
<span class="n">OUTPUT_DIM</span> <span class="o">=</span> <span class="mi">1000</span>
<span class="n">ENC_EMB_DIM</span> <span class="o">=</span> <span class="mi">256</span>
<span class="n">DEC_EMB_DIM</span> <span class="o">=</span> <span class="mi">256</span>
<span class="n">HID_DIM</span> <span class="o">=</span> <span class="mi">512</span>
<span class="n">N_LAYERS</span> <span class="o">=</span> <span class="mi">2</span>
<span class="n">ENC_DROPOUT</span> <span class="o">=</span> <span class="mf">0.5</span>
<span class="n">DEC_DROPOUT</span> <span class="o">=</span> <span class="mf">0.5</span>
<span class="n">device</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="nf">device</span><span class="p">(</span><span class="sh">'</span><span class="s">cuda</span><span class="sh">'</span> <span class="k">if</span> <span class="n">torch</span><span class="p">.</span><span class="n">cuda</span><span class="p">.</span><span class="nf">is_available</span><span class="p">()</span> <span class="k">else</span> <span class="sh">'</span><span class="s">cpu</span><span class="sh">'</span><span class="p">)</span>

<span class="n">enc</span> <span class="o">=</span> <span class="nc">Encoder</span><span class="p">(</span><span class="n">INPUT_DIM</span><span class="p">,</span> <span class="n">ENC_EMB_DIM</span><span class="p">,</span> <span class="n">HID_DIM</span><span class="p">,</span> <span class="n">N_LAYERS</span><span class="p">,</span> <span class="n">ENC_DROPOUT</span><span class="p">)</span>
<span class="n">dec</span> <span class="o">=</span> <span class="nc">Decoder</span><span class="p">(</span><span class="n">OUTPUT_DIM</span><span class="p">,</span> <span class="n">DEC_EMB_DIM</span><span class="p">,</span> <span class="n">HID_DIM</span><span class="p">,</span> <span class="n">N_LAYERS</span><span class="p">,</span> <span class="n">DEC_DROPOUT</span><span class="p">)</span>
<span class="n">model</span> <span class="o">=</span> <span class="nc">Seq2Seq</span><span class="p">(</span><span class="n">enc</span><span class="p">,</span> <span class="n">dec</span><span class="p">,</span> <span class="n">device</span><span class="p">).</span><span class="nf">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>

<span class="n">optimizer</span> <span class="o">=</span> <span class="n">optim</span><span class="p">.</span><span class="nc">Adam</span><span class="p">(</span><span class="n">model</span><span class="p">.</span><span class="nf">parameters</span><span class="p">())</span>
<span class="n">criterion</span> <span class="o">=</span> <span class="n">nn</span><span class="p">.</span><span class="nc">CrossEntropyLoss</span><span class="p">()</span>


<span class="k">def</span> <span class="nf">train</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">iterator</span><span class="p">,</span> <span class="n">optimizer</span><span class="p">,</span> <span class="n">criterion</span><span class="p">,</span> <span class="n">clip</span><span class="p">):</span>
    <span class="n">model</span><span class="p">.</span><span class="nf">train</span><span class="p">()</span>
    <span class="n">epoch_loss</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="n">count</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="p">(</span><span class="n">src</span><span class="p">,</span> <span class="n">trg</span><span class="p">)</span> <span class="ow">in</span> <span class="nf">enumerate</span><span class="p">(</span><span class="n">iterator</span><span class="p">):</span>
        <span class="n">optimizer</span><span class="p">.</span><span class="nf">zero_grad</span><span class="p">()</span>
        <span class="n">output</span> <span class="o">=</span> <span class="nf">model</span><span class="p">(</span><span class="n">src</span><span class="p">,</span> <span class="n">trg</span><span class="p">)</span>
        <span class="n">output_dim</span> <span class="o">=</span> <span class="n">output</span><span class="p">.</span><span class="n">shape</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>
        <span class="n">output</span> <span class="o">=</span> <span class="n">output</span><span class="p">[</span><span class="mi">1</span><span class="p">:].</span><span class="nf">view</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="n">output_dim</span><span class="p">)</span>
        <span class="n">trg</span> <span class="o">=</span> <span class="n">trg</span><span class="p">[</span><span class="mi">1</span><span class="p">:].</span><span class="nf">view</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span>
        <span class="n">loss</span> <span class="o">=</span> <span class="nf">criterion</span><span class="p">(</span><span class="n">output</span><span class="p">,</span> <span class="n">trg</span><span class="p">)</span>
        <span class="n">loss</span><span class="p">.</span><span class="nf">backward</span><span class="p">()</span>
        <span class="n">torch</span><span class="p">.</span><span class="n">nn</span><span class="p">.</span><span class="n">utils</span><span class="p">.</span><span class="nf">clip_grad_norm_</span><span class="p">(</span><span class="n">model</span><span class="p">.</span><span class="nf">parameters</span><span class="p">(),</span> <span class="n">clip</span><span class="p">)</span>
        <span class="n">optimizer</span><span class="p">.</span><span class="nf">step</span><span class="p">()</span>
        <span class="n">epoch_loss</span> <span class="o">+=</span> <span class="n">loss</span><span class="p">.</span><span class="nf">item</span><span class="p">()</span>
        <span class="n">count</span> <span class="o">=</span> <span class="n">i</span>
    <span class="k">return</span> <span class="n">epoch_loss</span> <span class="o">/</span> <span class="p">(</span><span class="n">count</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span>


<span class="k">def</span> <span class="nf">main</span><span class="p">():</span>
    <span class="n">src</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="nf">randint</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">INPUT_DIM</span><span class="p">,</span> <span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="mi">32</span><span class="p">)).</span><span class="nf">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>  <span class="c1"># sequence length 10, batch szie 32
</span>    <span class="n">trg</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="nf">randint</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">OUTPUT_DIM</span><span class="p">,</span> <span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="mi">32</span><span class="p">)).</span><span class="nf">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
    <span class="n">dataset</span> <span class="o">=</span> <span class="p">[(</span><span class="n">src</span><span class="p">,</span> <span class="n">trg</span><span class="p">)</span> <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nf">range</span><span class="p">(</span><span class="mi">100</span><span class="p">)]</span>  <span class="c1"># 100 batch
</span>    <span class="n">iterator</span> <span class="o">=</span> <span class="nf">iter</span><span class="p">(</span><span class="n">dataset</span><span class="p">)</span>

    <span class="n">N_EPOCHS</span> <span class="o">=</span> <span class="mi">10</span>
    <span class="n">CLIP</span> <span class="o">=</span> <span class="mi">1</span>
    <span class="k">for</span> <span class="n">epoch</span> <span class="ow">in</span> <span class="nf">range</span><span class="p">(</span><span class="n">N_EPOCHS</span><span class="p">):</span>
        <span class="n">train_loss</span> <span class="o">=</span> <span class="nf">train</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">iterator</span><span class="p">,</span> <span class="n">optimizer</span><span class="p">,</span> <span class="n">criterion</span><span class="p">,</span> <span class="n">CLIP</span><span class="p">)</span>
        <span class="nf">print</span><span class="p">(</span><span class="sa">f</span><span class="sh">'</span><span class="s">Epoch: </span><span class="si">{</span><span class="n">epoch</span> <span class="o">+</span> <span class="mi">1</span><span class="si">:</span><span class="mi">02</span><span class="si">}</span><span class="s"> | Train Loss: </span><span class="si">{</span><span class="n">train_loss</span><span class="si">:</span><span class="p">.</span><span class="mi">3</span><span class="n">f</span><span class="si">}</span><span class="sh">'</span><span class="p">)</span>


<span class="k">def</span> <span class="nf">evaluate</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">iterator</span><span class="p">,</span> <span class="n">criterion</span><span class="p">):</span>
    <span class="n">model</span><span class="p">.</span><span class="nf">eval</span><span class="p">()</span>
    <span class="n">epoch_loss</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="n">count</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="k">with</span> <span class="n">torch</span><span class="p">.</span><span class="nf">no_grad</span><span class="p">():</span>
        <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="p">(</span><span class="n">src</span><span class="p">,</span> <span class="n">trg</span><span class="p">)</span> <span class="ow">in</span> <span class="nf">enumerate</span><span class="p">(</span><span class="n">iterator</span><span class="p">):</span>
            <span class="n">output</span> <span class="o">=</span> <span class="nf">model</span><span class="p">(</span><span class="n">src</span><span class="p">,</span> <span class="n">trg</span><span class="p">,</span> <span class="mi">0</span><span class="p">)</span>  <span class="c1"># 0 means not using teacher forcing
</span>            <span class="n">output_dim</span> <span class="o">=</span> <span class="n">output</span><span class="p">.</span><span class="n">shape</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>
            <span class="n">output</span> <span class="o">=</span> <span class="n">output</span><span class="p">[</span><span class="mi">1</span><span class="p">:].</span><span class="nf">view</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="n">output_dim</span><span class="p">)</span>
            <span class="n">trg</span> <span class="o">=</span> <span class="n">trg</span><span class="p">[</span><span class="mi">1</span><span class="p">:].</span><span class="nf">view</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span>
            <span class="n">loss</span> <span class="o">=</span> <span class="nf">criterion</span><span class="p">(</span><span class="n">output</span><span class="p">,</span> <span class="n">trg</span><span class="p">)</span>
            <span class="n">epoch_loss</span> <span class="o">+=</span> <span class="n">loss</span><span class="p">.</span><span class="nf">item</span><span class="p">()</span>
            <span class="n">count</span> <span class="o">=</span> <span class="n">i</span>
    <span class="k">return</span> <span class="n">epoch_loss</span> <span class="o">/</span> <span class="p">(</span><span class="n">count</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span>


<span class="k">def</span> <span class="nf">main_test</span><span class="p">():</span>
    <span class="n">src_test</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="nf">randint</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">INPUT_DIM</span><span class="p">,</span> <span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="mi">32</span><span class="p">)).</span><span class="nf">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>  <span class="c1"># sequence_length 10,  batchsize 32
</span>    <span class="n">trg_test</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="nf">randint</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">OUTPUT_DIM</span><span class="p">,</span> <span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="mi">32</span><span class="p">)).</span><span class="nf">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
    <span class="n">test_dataset</span> <span class="o">=</span> <span class="p">[(</span><span class="n">src_test</span><span class="p">,</span> <span class="n">trg_test</span><span class="p">)</span> <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nf">range</span><span class="p">(</span><span class="mi">50</span><span class="p">)]</span>  <span class="c1"># 50 batch
</span>    <span class="n">test_iterator</span> <span class="o">=</span> <span class="nf">iter</span><span class="p">(</span><span class="n">test_dataset</span><span class="p">)</span>

    <span class="n">test_loss</span> <span class="o">=</span> <span class="nf">evaluate</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">test_iterator</span><span class="p">,</span> <span class="n">criterion</span><span class="p">)</span>
    <span class="nf">print</span><span class="p">(</span><span class="sa">f</span><span class="sh">'</span><span class="s">Test Loss: </span><span class="si">{</span><span class="n">test_loss</span><span class="si">:</span><span class="p">.</span><span class="mi">3</span><span class="n">f</span><span class="si">}</span><span class="sh">'</span><span class="p">)</span>


<span class="k">if</span> <span class="n">__name__</span> <span class="o">==</span> <span class="sh">"</span><span class="s">__main__</span><span class="sh">"</span><span class="p">:</span>
    <span class="nf">main</span><span class="p">()</span>
    <span class="nf">main_test</span><span class="p">()</span>

</pre></td></tr></tbody></table></code></div></div>

<hr />

<h2 id="transformer"><span class="me-2"><a href="https://d2l.ai/chapter_attention-mechanisms-and-transformers/index.html">Transformer</a></span><a href="#transformer" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h2>

<blockquote class="prompt-info">
  <p>The <strong>Transformer</strong>, <strong>BERT</strong>, and <strong>GPT</strong> architectures do not use <strong>RNNs</strong>. Instead, they rely on the <strong>self-attention</strong> mechanism to process sequences.  <em>— ChatGPT 4</em></p>
</blockquote>

<h3 id="queries-keys-and-values"><span class="me-2">Queries, Keys, and Values</span><a href="#queries-keys-and-values" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h3>

<ul>
  <li>A data set $\mathcal{D}:={ (k_i, v_i) \mid i\in {1, \ldots, n} }$.
    <ul>
      <li>$k$ is the key, $v$ is the value.</li>
      <li>It is a dictionary (in python).</li>
    </ul>
  </li>
  <li>We input the query $q$ to search the data set.</li>
  <li>The program returns the value most relevant $v_{i^*}$, where $i^* = \arg\min_{i} \Vert q - x_i \Vert$.</li>
</ul>

<div class="language-python highlighter-rouge"><div class="code-header">
        <span data-label-text="Python"><i class="fas fa-code fa-fw small"></i></span>
      <button aria-label="copy" data-title-succeed="Copied!"><i class="far fa-clipboard"></i></button></div><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
9
10
11
12
13
14
</pre></td><td class="rouge-code"><pre><span class="n">keys</span> <span class="o">=</span> <span class="nf">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">8</span><span class="p">,</span> <span class="mi">3</span><span class="p">)</span>  <span class="c1"># [1, 4, 7]
</span><span class="n">values</span> <span class="o">=</span> <span class="p">[</span><span class="sh">"</span><span class="s">xixi</span><span class="sh">"</span><span class="p">,</span> <span class="sh">"</span><span class="s">haha</span><span class="sh">"</span><span class="p">,</span> <span class="sh">"</span><span class="s">wuwu</span><span class="sh">"</span><span class="p">]</span>

<span class="n">data_set</span> <span class="o">=</span> <span class="nf">dict</span><span class="p">(</span><span class="nf">zip</span><span class="p">(</span><span class="n">keys</span><span class="p">,</span> <span class="n">values</span><span class="p">))</span>
<span class="c1"># {1: 'xixi', 4: 'haha', 7: 'wuwu'}
</span>
<span class="k">def</span> <span class="nf">search</span><span class="p">(</span><span class="n">query</span><span class="p">:</span> <span class="nb">int</span><span class="p">):</span>
    <span class="n">distances</span> <span class="o">=</span> <span class="p">[</span><span class="nf">abs</span><span class="p">(</span><span class="n">query</span> <span class="o">-</span> <span class="n">key_i</span><span class="p">)</span> <span class="k">for</span> <span class="n">key_i</span> <span class="ow">in</span> <span class="n">keys</span><span class="p">]</span>
    <span class="n">idx_optimal</span> <span class="o">=</span> <span class="n">distances</span><span class="p">.</span><span class="nf">index</span><span class="p">(</span><span class="nf">min</span><span class="p">(</span><span class="n">distances</span><span class="p">))</span>
    <span class="n">key_optimal</span> <span class="o">=</span> <span class="n">keys</span><span class="p">[</span><span class="n">idx_optimal</span><span class="p">]</span>
    <span class="n">value_optimal</span> <span class="o">=</span> <span class="n">data_set</span><span class="p">[</span><span class="n">key_optimal</span><span class="p">]</span>
    <span class="k">return</span> <span class="n">value_optimal</span>

<span class="nf">print</span><span class="p">(</span><span class="nf">search</span><span class="p">(</span><span class="n">query</span><span class="o">=</span><span class="mi">3</span><span class="p">))</span>  <span class="c1"># haha
</span></pre></td></tr></tbody></table></code></div></div>

<h3 id="attention"><span class="me-2">Attention</span><a href="#attention" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h3>
<blockquote>
  <p>Attention is all you need.</p>
</blockquote>

\[\mathrm{Attention}(q, \mathcal{D}) := \sum\limits_{i=1}^n v_i \cdot \alpha(q, k_i)\]

<ul>
  <li>$\alpha(q, k_i)$ is usually a function of the distance between $q$ and $k_i$, reflecting their similarity.</li>
  <li>$\boldsymbol\alpha = (\alpha(q, k_1), \ldots, \alpha(q, k_n))$ should be a convex combination.
    <ul>
      <li>$\alpha(q, k_i) \ge 0, \forall i$</li>
      <li>$\sum\limits_{i=1}^n \alpha(q, k_i) = 1$</li>
    </ul>
  </li>
  <li>If $\boldsymbol\alpha$ is one-hot, then the attention mechanism is just like the traditional database query.</li>
</ul>

<p><a href="https://d2l.ai/_images/qkv.svg" class="popup img-link  shimmer"><img src="https://d2l.ai/_images/qkv.svg" alt="Attention" width="500" height="500" loading="lazy"></a>
<em>Illustration of the attention mechanism from the book “Dive into Deep Learning”.</em></p>

<h4 id="common-similarity-kernels"><span class="me-2">Common similarity kernels</span><a href="#common-similarity-kernels" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h4>

\[\boldsymbol\alpha(q, \boldsymbol{k}) = \mathrm{softmax}(\textcolor{blue}{(}f(\Vert q - k_1 \Vert), \ldots, f(\Vert q - k_n \Vert)\textcolor{blue}{)})\]

<p>$f$ is the similarity kernel (or Parzen Windows).</p>
<ul>
  <li>$f(\Vert q - k \Vert) = \exp\left(-\frac{1}{2}\Vert q-k \Vert^2\right)$ (Gaussian)</li>
  <li>$f(\Vert q - k \Vert) = 1 \mathrm{if} \Vert q-k \Vert \le 1$ (Boxcar)</li>
  <li>$f(\Vert q - k \Vert) = \max(0, 1- \Vert q-k \Vert )$ (Epanechikov)</li>
</ul>

<h3 id="attention-scoring-functions"><span class="me-2">Attention Scoring Functions</span><a href="#attention-scoring-functions" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h3>

<p>Calculating the distances between queries and keys costs a lot. So we should find another efficient way to quantify the similarity between them. The function that measures this similarity is named the scoring function.</p>

<p><a href="https://d2l.ai/_images/attention-output.svg" class="popup img-link  shimmer"><img src="https://d2l.ai/_images/attention-output.svg" alt="Scoring" width="500" height="500" loading="lazy"></a>
<em>Illustration of the attention mechanism from the book “Dive into Deep Learning”.</em></p>

<blockquote class="prompt-warning">
  <p>The following part has not been finished yet. One may check my <a href="https://yuelin301.github.io/posts/Schedule/">writing schedule</a>.</p>
</blockquote>

<h2 id="bert"><span class="me-2">BERT</span><a href="#bert" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h2>
<p>BERT = Bidirectional Encoder Representations from Transformers</p>

<h2 id="gpt"><span class="me-2">GPT</span><a href="#gpt" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h2>

<p>GPT = Generative Pre-trained Transformer</p>

  </div>

  <div class="post-tail-wrapper text-muted">
    <!-- categories -->
    
      <div class="post-meta mb-3">
        <i class="far fa-folder-open fa-fw me-1"></i>
        
          <a href="/categories/artificial-intelligence/">Artificial Intelligence</a>,
          <a href="/categories/machine-learning-basics/">Machine Learning Basics</a>
      </div>
    

    <!-- tags -->
    
      <div class="post-tags">
        <i class="fa fa-tags fa-fw me-1"></i>
        
          <a
            href="/tags/tech/"
            class="post-tag no-text-decoration"
          >tech</a>
        
          <a
            href="/tags/nlp/"
            class="post-tag no-text-decoration"
          >NLP</a>
        
          <a
            href="/tags/rnn/"
            class="post-tag no-text-decoration"
          >RNN</a>
        
          <a
            href="/tags/lstm/"
            class="post-tag no-text-decoration"
          >LSTM</a>
        
          <a
            href="/tags/gru/"
            class="post-tag no-text-decoration"
          >GRU</a>
        
          <a
            href="/tags/seq2seq/"
            class="post-tag no-text-decoration"
          >Seq2Seq</a>
        
          <a
            href="/tags/transformer/"
            class="post-tag no-text-decoration"
          >transformer</a>
        
          <a
            href="/tags/bert/"
            class="post-tag no-text-decoration"
          >BERT</a>
        
          <a
            href="/tags/gpt/"
            class="post-tag no-text-decoration"
          >GPT</a>
        
      </div>
    

    <div
      class="
        post-tail-bottom
        d-flex justify-content-between align-items-center mt-5 pb-2
      "
    >
      <div class="license-wrapper">
        
          

          This post is licensed under 
        <a href="https://creativecommons.org/licenses/by/4.0/">
          CC BY 4.0
        </a>
         by the author.
        
      </div>

      <!-- Post sharing snippet -->

<div class="share-wrapper d-flex align-items-center">
  <span class="share-label text-muted me-1">Share</span>
  <span class="share-icons">
    
    
    

    
      
      <a
        href="https://twitter.com/intent/tweet?text=Sequence-to-Sequence%20Models%20-%20Yue%20Lin&url=http%3A%2F%2Flocalhost%3A4000%2Fposts%2FSeq2Seq%2F"
        data-bs-toggle="tooltip"
        data-bs-placement="top"
        title="Twitter"
        target="_blank"
        rel="noopener"
        aria-label="Twitter"
      >
        <i class="fa-fw fa-brands fa-square-x-twitter"></i>
      </a>
    
      
      <a
        href="https://www.facebook.com/sharer/sharer.php?title=Sequence-to-Sequence%20Models%20-%20Yue%20Lin&u=http%3A%2F%2Flocalhost%3A4000%2Fposts%2FSeq2Seq%2F"
        data-bs-toggle="tooltip"
        data-bs-placement="top"
        title="Facebook"
        target="_blank"
        rel="noopener"
        aria-label="Facebook"
      >
        <i class="fa-fw fab fa-facebook-square"></i>
      </a>
    
      
      <a
        href="https://t.me/share/url?url=http%3A%2F%2Flocalhost%3A4000%2Fposts%2FSeq2Seq%2F&text=Sequence-to-Sequence%20Models%20-%20Yue%20Lin"
        data-bs-toggle="tooltip"
        data-bs-placement="top"
        title="Telegram"
        target="_blank"
        rel="noopener"
        aria-label="Telegram"
      >
        <i class="fa-fw fab fa-telegram"></i>
      </a>
    

    <button
      id="copy-link"
      aria-label="Copy link"
      class="btn small"
      data-bs-toggle="tooltip"
      data-bs-placement="top"
      title="Copy link"
      data-title-succeed="Link copied successfully!"
    >
      <i class="fa-fw fas fa-link pe-none"></i>
    </button>
  </span>
</div>

    </div>
    <!-- .post-tail-bottom -->
  </div>
  <!-- div.post-tail-wrapper -->
</article>


            
          </main>

          <!-- panel -->
          <!-- <aside aria-label="Panel" id="panel-wrapper" class="col-xl-3 ps-2 mb-5 text-muted"> -->
          <aside aria-label="Panel" id="panel-wrapper" class="col-12 col-sm-3 col-lg-3 col-xl-3 ps-2 mb-5 text-muted">
            <div class="access">
              <!-- Get the last 5 posts from lastmod list. -->














  <section id="access-lastmod">
    <h2 class="panel-heading">Recently Updated</h2>
    <ul class="content list-unstyled ps-0 pb-1 ms-1 mt-2">
      
        
        
        
        <li class="text-truncate lh-lg">
          <a href="/posts/English-Toolbox/">English Toolbox</a>
        </li>
      
        
        
        
        <li class="text-truncate lh-lg">
          <a href="/posts/Personality/">Personality</a>
        </li>
      
        
        
        
        <li class="text-truncate lh-lg">
          <a href="/posts/MARL-Tasks/">MARL Tasks</a>
        </li>
      
        
        
        
        <li class="text-truncate lh-lg">
          <a href="/posts/Information-Design-10min/">Information Design in 10 Minutes</a>
        </li>
      
    </ul>
  </section>
  <!-- #access-lastmod -->


              <!-- The trending tags list -->















  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
      
        
        

  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
      
        
        

  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
      
        
        

  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
      
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
      
        
        

  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
      
        
        

  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
      
        
        

  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
      
        
        



  <section>
    <h2 class="panel-heading">Trending Tags</h2>
    <div class="d-flex flex-wrap mt-3 mb-1 me-3">
      
        
        <a class="post-tag btn btn-outline-primary" href="/tags/tech/">tech</a>
      
        
        <a class="post-tag btn btn-outline-primary" href="/tags/multi-agents/">multi agents</a>
      
        
        <a class="post-tag btn btn-outline-primary" href="/tags/math/">math</a>
      
        
        <a class="post-tag btn btn-outline-primary" href="/tags/reinforcement-learning/">reinforcement learning</a>
      
        
        <a class="post-tag btn btn-outline-primary" href="/tags/game-theory/">game theory</a>
      
        
        <a class="post-tag btn btn-outline-primary" href="/tags/life/">life</a>
      
        
        <a class="post-tag btn btn-outline-primary" href="/tags/efficiency/">efficiency</a>
      
    </div>
  </section>


            </div>

            
              
              



  <section id="toc-wrapper" class="ps-0 pe-4">
    <h2 class="panel-heading ps-3 pt-2 mb-2">Contents</h2>
    <nav id="toc"></nav>
  </section>


            
          </aside>
        </div>

        <div class="row">
          <!-- tail -->
          <div id="tail-wrapper" class="col-12 col-lg-11 col-xl-9 px-md-4">
            
              
              <!-- Recommend the other 3 posts according to the tags and categories of the current post. -->

<!-- The total size of related posts -->


<!-- An random integer that bigger than 0 -->


<!-- Equals to TAG_SCORE / {max_categories_hierarchy} -->














  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  
    
  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  











  <aside id="related-posts" aria-labelledby="related-label">
    <h3 class="mb-4" id="related-label">Further Reading</h3>
    <nav class="row row-cols-1 row-cols-md-2 row-cols-xl-3 g-4 mb-4">
      
        <article class="col">
          <a href="/posts/Decision-Transformers/" class="post-preview card h-100">
            <div class="card-body">
              <!--
  Date format snippet
  See: ${JS_ROOT}/utils/locale-dateime.js
-->




<time
  
  data-ts="1699728000"
  data-df="ll"
  
>
  Nov 11, 2023
</time>

              <h4 class="pt-0 my-2">Decision Transformers</h4>
              <div class="text-muted">
                <p>
                  





                  Decision Transformer


  Paper: Decision Transformer: Reinforcement Learning via Sequence Modeling - NeurIPS 2021
  [Website]
[Code]



Illustration from the corresponding paper.


Illustration fro...
                </p>
              </div>
            </div>
          </a>
        </article>
      
        <article class="col">
          <a href="/posts/Policy-Gradient-Details/" class="post-preview card h-100">
            <div class="card-body">
              <!--
  Date format snippet
  See: ${JS_ROOT}/utils/locale-dateime.js
-->




<time
  
  data-ts="1690224000"
  data-df="ll"
  
>
  Jul 24, 2023
</time>

              <h4 class="pt-0 my-2">Details on the Analysis of Policy Gradient Methods</h4>
              <div class="text-muted">
                <p>
                  





                  
  The only way to make sense out of change is to plunge into it, move with it, and join the dance. — Alan Watts.




Policy Gradient Theorem


  The proofs of the stochastic and deterministic poli...
                </p>
              </div>
            </div>
          </a>
        </article>
      
        <article class="col">
          <a href="/posts/HyperNetworks/" class="post-preview card h-100">
            <div class="card-body">
              <!--
  Date format snippet
  See: ${JS_ROOT}/utils/locale-dateime.js
-->




<time
  
  data-ts="1699900800"
  data-df="ll"
  
>
  Nov 13, 2023
</time>

              <h4 class="pt-0 my-2">HyperNetworks</h4>
              <div class="text-muted">
                <p>
                  





                  Introduction
[Paper]: HyperNetworks


  The following part has not been finished yet.


Application in QMIX


Illustration from the corresponding paper.

The following statements from the paper are...
                </p>
              </div>
            </div>
          </a>
        </article>
      
    </nav>
  </aside>
  <!-- #related-posts -->


            
              
              <!-- Navigation buttons at the bottom of the post. -->

<nav class="post-navigation d-flex justify-content-between" aria-label="Post Navigation">
  
  

  
    <a
      href="/posts/MARL-Basics/"
      class="btn btn-outline-primary"
      aria-label="Older"
    >
      <p>MARL Basics</p>
    </a>
  

  
    <a
      href="/posts/Policy-Gradient-Details/"
      class="btn btn-outline-primary"
      aria-label="Newer"
    >
      <p>Details on the Analysis of Policy Gradient Methods</p>
    </a>
  
</nav>

            
              
              <!--  The comments switcher -->


            

            <!-- The Footer -->

<footer
  aria-label="Site Info"
  class="
    d-flex flex-column justify-content-center text-muted
    flex-lg-row justify-content-lg-between align-items-lg-center pb-lg-3
  "
>
  <p>
    ©
    <time>2023</time>
    <a href="https://github.com/YueLin301">Yue Lin</a>.
    
      <span
        data-bs-toggle="tooltip"
        data-bs-placement="top"
        title="Except where otherwise noted, the blog posts on this site are licensed under the Creative Commons Attribution 4.0 International (CC BY 4.0) License by the author."
      >Some rights reserved.</span>
    
  </p>

  <p>Adapted from the <a href="https://github.com/cotes2020/jekyll-theme-chirpy" target="_blank" rel="noopener">Chirpy</a> theme for <a href="https://jekyllrb.com" target="_blank" rel="noopener">Jekyll</a>
  </p>
</footer>

          </div>
        </div>

        <!-- The Search results -->

<div id="search-result-wrapper" class="d-flex justify-content-center unloaded">
  <div class="col-11 content">
    <div id="search-hints">
      <!-- The trending tags list -->















  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
      
        
        

  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
      
        
        

  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
      
        
        

  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
      
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
      
        
        

  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
      
        
        

  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
      
        
        

  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
      
        
        



  <section>
    <h2 class="panel-heading">Trending Tags</h2>
    <div class="d-flex flex-wrap mt-3 mb-1 me-3">
      
        
        <a class="post-tag btn btn-outline-primary" href="/tags/tech/">tech</a>
      
        
        <a class="post-tag btn btn-outline-primary" href="/tags/multi-agents/">multi agents</a>
      
        
        <a class="post-tag btn btn-outline-primary" href="/tags/math/">math</a>
      
        
        <a class="post-tag btn btn-outline-primary" href="/tags/reinforcement-learning/">reinforcement learning</a>
      
        
        <a class="post-tag btn btn-outline-primary" href="/tags/game-theory/">game theory</a>
      
        
        <a class="post-tag btn btn-outline-primary" href="/tags/life/">life</a>
      
        
        <a class="post-tag btn btn-outline-primary" href="/tags/efficiency/">efficiency</a>
      
    </div>
  </section>


    </div>
    <div id="search-results" class="d-flex flex-wrap justify-content-center text-muted mt-3"></div>
  </div>
</div>

      </div>

      <aside aria-label="Scroll to Top">
        <button id="back-to-top" type="button" class="btn btn-lg btn-box-shadow">
          <i class="fas fa-angle-up"></i>
        </button>
      </aside>
    </div>

    <div id="mask"></div>

    
      <aside
  id="notification"
  class="toast"
  role="alert"
  aria-live="assertive"
  aria-atomic="true"
  data-bs-animation="true"
  data-bs-autohide="false"
>
  <div class="toast-header">
    <button
      type="button"
      class="btn-close ms-auto"
      data-bs-dismiss="toast"
      aria-label="Close"
    ></button>
  </div>
  <div class="toast-body text-center pt-0">
    <p class="px-2 mb-3">A new version of content is available.</p>
    <button type="button" class="btn btn-primary" aria-label="Update">
      Update
    </button>
  </div>
</aside>

    

    <!-- JavaScripts -->

    <!-- JS selector for site. -->

<!-- commons -->



<!-- layout specified -->


  

  
    <!-- image lazy-loading & popup & clipboard -->
    
  















  
    

    

  

  
    

    

  

  
    

    

  

  
    

    

  

  
    

    

  

  
    

    

  

  
    

    

  

  
    

    

  

  
    

    

  

  
    

    

  

  
    

    

  



  <script src="https://cdn.jsdelivr.net/combine/npm/jquery@3.7.1/dist/jquery.min.js,npm/bootstrap@5.3.2/dist/js/bootstrap.bundle.min.js,npm/simple-jekyll-search@1.10.0/dest/simple-jekyll-search.min.js,npm/loading-attribute-polyfill@2.1.1/dist/loading-attribute-polyfill.umd.min.js,npm/magnific-popup@1.1.0/dist/jquery.magnific-popup.min.js,npm/clipboard@2.0.11/dist/clipboard.min.js,npm/dayjs@1.11.10/dayjs.min.js,npm/dayjs@1.11.10/locale/en.min.js,npm/dayjs@1.11.10/plugin/relativeTime.min.js,npm/dayjs@1.11.10/plugin/localizedFormat.min.js,npm/tocbot@4.21.1/dist/tocbot.min.js"></script>






<script defer src="/assets/js/dist/post.min.js"></script>


  <!-- MathJax -->
  <script>
    /* see: <https://docs.mathjax.org/en/latest/options/input/tex.html#tex-options> */
    MathJax = {
      tex: {
        /* start/end delimiter pairs for in-line math */
        inlineMath: [
          ['$', '$'],
          ['\\(', '\\)']
        ],
        /* start/end delimiter pairs for display math */
        displayMath: [
          ['$$', '$$'],
          ['\\[', '\\]']
        ]
      }
    };
  </script>
  <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
  <script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3.2.2/es5/tex-chtml.js"></script>





    

    <!--
  Jekyll Simple Search loader
  See: <https://github.com/christian-fei/Simple-Jekyll-Search>
-->





<script>
  /* Note: dependent library will be loaded in `js-selector.html` */
  SimpleJekyllSearch({
    searchInput: document.getElementById('search-input'),
    resultsContainer: document.getElementById('search-results'),
    json: '/assets/js/data/search.json',
    searchResultTemplate: '  <article class="px-1 px-sm-2 px-lg-4 px-xl-0">    <header>      <h2><a href="{url}">{title}</a></h2>      <div class="post-meta d-flex flex-column flex-sm-row text-muted mt-1 mb-1">        {categories}        {tags}      </div>    </header>    <p>{snippet}</p>  </article>',
    noResultsText: '<p class="mt-5"></p>',
    templateMiddleware: function(prop, value, template) {
      if (prop === 'categories') {
        if (value === '') {
          return `${value}`;
        } else {
          return `<div class="me-sm-4"><i class="far fa-folder fa-fw"></i>${value}</div>`;
        }
      }

      if (prop === 'tags') {
        if (value === '') {
          return `${value}`;
        } else {
          return `<div><i class="fa fa-tag fa-fw"></i>${value}</div>`;
        }
      }
    }
  });
</script>

  </body>
</html>

